{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd802cde-09a7-49be-a23c-ab823b5a54b2",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70beee33-3565-416d-8716-b4aa02c72131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "# scikit-learn: iterative imputer setup\n",
    "from sklearn.experimental import enable_iterative_imputer  \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# Global pandas display settings for easier inspection\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 150)\n",
    "pd.set_option(\"display.precision\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d9bc11-6a1a-468d-9b8d-bf4e3b3cdd93",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb16a31-f98c-4486-b153-7df44de1e7e9",
   "metadata": {},
   "source": [
    "### Part I: Outcome Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e050d5c2-8ee0-4ffc-b725-0c17957b6b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_y shape: (74922, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>returned_12m</th>\n",
       "      <th>weight_12m</th>\n",
       "      <th>weight_intensive_12m</th>\n",
       "      <th>weight_newlottery_12m</th>\n",
       "      <th>cost_any_owe_12m</th>\n",
       "      <th>cost_tot_owe_12m</th>\n",
       "      <th>cost_borrow_12m</th>\n",
       "      <th>cost_refused_12m</th>\n",
       "      <th>cost_tot_oop_12m</th>\n",
       "      <th>cost_any_oop_12m</th>\n",
       "      <th>hhinc_cat_12m</th>\n",
       "      <th>cost_doc_oop_12m</th>\n",
       "      <th>cost_er_oop_12m</th>\n",
       "      <th>cost_rx_oop_12m</th>\n",
       "      <th>cost_oth_oop_12m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_id  returned_12m  weight_12m  weight_intensive_12m  weight_newlottery_12m  cost_any_owe_12m  cost_tot_owe_12m  cost_borrow_12m  \\\n",
       "0          1           1.0         1.0                   1.0                  1.000               0.0               0.0              1.0   \n",
       "1          2           1.0         1.0                   1.0                  1.000               0.0               0.0              0.0   \n",
       "2          3           0.0         0.0                   0.0                  1.047               NaN               NaN              NaN   \n",
       "3          4           NaN         NaN                   NaN                    NaN               NaN               NaN              NaN   \n",
       "4          5           1.0         1.0                   1.0                  1.000               0.0               0.0              0.0   \n",
       "\n",
       "   cost_refused_12m  cost_tot_oop_12m  cost_any_oop_12m  hhinc_cat_12m  cost_doc_oop_12m  cost_er_oop_12m  cost_rx_oop_12m  cost_oth_oop_12m  \n",
       "0               0.0               0.0               0.0            1.0               0.0              0.0              0.0               0.0  \n",
       "1               NaN               0.0               0.0            5.0               0.0              0.0              0.0               0.0  \n",
       "2               NaN               NaN               NaN            NaN               NaN              NaN              NaN               NaN  \n",
       "3               NaN               NaN               NaN            NaN               NaN              NaN              NaN               NaN  \n",
       "4               0.0               0.0               0.0           11.0               0.0              0.0              0.0               0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path(\"../Data_Used\")\n",
    "\n",
    "# For 12m survey data\n",
    "# I will only pull columns for outcomes I need, no covariates as this is post-treatment\n",
    "col_keep_y = [\n",
    "    # --- A. Key & Filter Variables ---\n",
    "    'person_id',      # The unique ID to merge all files\n",
    "    'returned_12m',   # Later will restrict analysis sample to returned_12m == 1\n",
    "    'weight_12m',     # Survey weight adjusting for 12-month survey nonresponse\n",
    "    'weight_intensive_12m',\n",
    "    'weight_newlottery_12m',\n",
    "\n",
    "    # --- B. Primary Financial Outcomes (Y Variables) ---\n",
    "    # These variables directly measure financial hardship.\n",
    "    \n",
    "    # 1. Medical Debt\n",
    "    'cost_any_owe_12m',   # [1/0] Do they have *any* medical debt?\n",
    "    'cost_tot_owe_12m',   # [Num] How much medical debt do they have?\n",
    "\n",
    "    # 2. Financial Distress\n",
    "    'cost_borrow_12m',    # [1/0] Did they have to skip bills or borrow?\n",
    "    'cost_refused_12m',   # [1/0] Were they refused care for non-payment? \n",
    "\n",
    "    # These variables let us build our \"catastrophic\" outcome and\n",
    "    # conduct more detailed \"for what\" analysis.\n",
    "    \n",
    "    'cost_tot_oop_12m',   # [Num] Total Out-of-Pocket spending\n",
    "    'cost_any_oop_12m',   # [1/0] Any Out-of-Pocket spending\n",
    "    'hhinc_cat_12m',      # [Cat] Household income. \n",
    "                          \n",
    "    # 3. Detailed Spending (for secondary analysis)\n",
    "    'cost_doc_oop_12m',   # [Num] OOP spending on doctors\n",
    "    'cost_er_oop_12m',    # [Num] OOP spending on ER visits\n",
    "    'cost_rx_oop_12m',    # [Num] OOP spending on prescriptions (a key theoretical channel)\n",
    "    'cost_oth_oop_12m'    # [Num] OOP spending on other care\n",
    "]\n",
    "\n",
    "df_y_path = data_dir / \"oregonhie_survey12m_vars.dta\"\n",
    "df_y = pd.read_stata(\n",
    "    df_y_path,\n",
    "    columns=col_keep_y,\n",
    "    convert_categoricals=False,\n",
    "    preserve_dtypes=True\n",
    ")\n",
    "if df_y[\"person_id\"].isna().any():\n",
    "    raise ValueError(\"df_y has missing person_id values.\")\n",
    "\n",
    "df_y[\"person_id\"] = df_y[\"person_id\"].astype(\"int64\")\n",
    "\n",
    "print(\"df_y shape:\", df_y.shape)\n",
    "df_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26203de9-f4ca-44ae-af1a-af0c085c1caf",
   "metadata": {},
   "source": [
    "### Part 2: Covariate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75f279d1-cb7b-4813-90d2-92714c5e058b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_X shape: (74922, 43)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>returned_0m</th>\n",
       "      <th>surv_lang_0m</th>\n",
       "      <th>needmet_med_0m</th>\n",
       "      <th>needmet_rx_0m</th>\n",
       "      <th>rx_num_mod_0m</th>\n",
       "      <th>doc_num_mod_0m</th>\n",
       "      <th>er_num_mod_0m</th>\n",
       "      <th>hosp_num_mod_0m</th>\n",
       "      <th>need_rx_0m</th>\n",
       "      <th>need_med_0m</th>\n",
       "      <th>ins_months_0m</th>\n",
       "      <th>health_gen_0m</th>\n",
       "      <th>baddays_phys_0m</th>\n",
       "      <th>baddays_ment_0m</th>\n",
       "      <th>health_chg_0m</th>\n",
       "      <th>dia_dx_0m</th>\n",
       "      <th>ast_dx_0m</th>\n",
       "      <th>hbp_dx_0m</th>\n",
       "      <th>emp_dx_0m</th>\n",
       "      <th>chf_dx_0m</th>\n",
       "      <th>dep_dx_0m</th>\n",
       "      <th>female_0m</th>\n",
       "      <th>birthyear_0m</th>\n",
       "      <th>edu_0m</th>\n",
       "      <th>race_hisp_0m</th>\n",
       "      <th>race_white_0m</th>\n",
       "      <th>race_black_0m</th>\n",
       "      <th>race_amerindian_0m</th>\n",
       "      <th>race_asian_0m</th>\n",
       "      <th>race_pacific_0m</th>\n",
       "      <th>race_other_qn_0m</th>\n",
       "      <th>employ_0m</th>\n",
       "      <th>employ_hrs_0m</th>\n",
       "      <th>hhinc_cat_0m</th>\n",
       "      <th>hhsize_0m</th>\n",
       "      <th>num19_0m</th>\n",
       "      <th>cost_any_oop_0m</th>\n",
       "      <th>cost_borrow_0m</th>\n",
       "      <th>cost_any_owe_0m</th>\n",
       "      <th>cost_tot_owe_0m</th>\n",
       "      <th>cost_refused_0m</th>\n",
       "      <th>cost_tot_oop_correct_0m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_id  returned_0m surv_lang_0m  needmet_med_0m  needmet_rx_0m  rx_num_mod_0m  doc_num_mod_0m  er_num_mod_0m  hosp_num_mod_0m  need_rx_0m  \\\n",
       "0          1          0.0                          NaN            NaN            NaN             NaN            NaN              NaN         NaN   \n",
       "1          2          0.0                          NaN            NaN            NaN             NaN            NaN              NaN         NaN   \n",
       "2          3          0.0                          NaN            NaN            NaN             NaN            NaN              NaN         NaN   \n",
       "3          4          NaN                          NaN            NaN            NaN             NaN            NaN              NaN         NaN   \n",
       "4          5          0.0                          NaN            NaN            NaN             NaN            NaN              NaN         NaN   \n",
       "\n",
       "   need_med_0m  ins_months_0m  health_gen_0m  baddays_phys_0m  baddays_ment_0m  health_chg_0m  dia_dx_0m  ast_dx_0m  hbp_dx_0m  emp_dx_0m  \\\n",
       "0          NaN            NaN            NaN              NaN              NaN            NaN        NaN        NaN        NaN        NaN   \n",
       "1          NaN            NaN            NaN              NaN              NaN            NaN        NaN        NaN        NaN        NaN   \n",
       "2          NaN            NaN            NaN              NaN              NaN            NaN        NaN        NaN        NaN        NaN   \n",
       "3          NaN            NaN            NaN              NaN              NaN            NaN        NaN        NaN        NaN        NaN   \n",
       "4          NaN            NaN            NaN              NaN              NaN            NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "   chf_dx_0m  dep_dx_0m  female_0m  birthyear_0m  edu_0m  race_hisp_0m  race_white_0m  race_black_0m  race_amerindian_0m  race_asian_0m  \\\n",
       "0        NaN        NaN        NaN           NaN     NaN           NaN            NaN            NaN                 NaN            NaN   \n",
       "1        NaN        NaN        NaN           NaN     NaN           NaN            NaN            NaN                 NaN            NaN   \n",
       "2        NaN        NaN        NaN           NaN     NaN           NaN            NaN            NaN                 NaN            NaN   \n",
       "3        NaN        NaN        NaN           NaN     NaN           NaN            NaN            NaN                 NaN            NaN   \n",
       "4        NaN        NaN        NaN           NaN     NaN           NaN            NaN            NaN                 NaN            NaN   \n",
       "\n",
       "   race_pacific_0m  race_other_qn_0m  employ_0m  employ_hrs_0m  hhinc_cat_0m  hhsize_0m  num19_0m  cost_any_oop_0m  cost_borrow_0m  cost_any_owe_0m  \\\n",
       "0              NaN               NaN        NaN            NaN           NaN        NaN       NaN              NaN             NaN              NaN   \n",
       "1              NaN               NaN        NaN            NaN           NaN        NaN       NaN              NaN             NaN              NaN   \n",
       "2              NaN               NaN        NaN            NaN           NaN        NaN       NaN              NaN             NaN              NaN   \n",
       "3              NaN               NaN        NaN            NaN           NaN        NaN       NaN              NaN             NaN              NaN   \n",
       "4              NaN               NaN        NaN            NaN           NaN        NaN       NaN              NaN             NaN              NaN   \n",
       "\n",
       "   cost_tot_owe_0m  cost_refused_0m  cost_tot_oop_correct_0m  \n",
       "0              NaN              NaN                      NaN  \n",
       "1              NaN              NaN                      NaN  \n",
       "2              NaN              NaN                      NaN  \n",
       "3              NaN              NaN                      NaN  \n",
       "4              NaN              NaN                      NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For 0m survey data\n",
    "# To pull covariates (X)\n",
    "\n",
    "col_keep_X = [\n",
    "    # --- A. Key & Filter Variables ---\n",
    "    'person_id',         # The unique ID to merge all files\n",
    "    'returned_0m',       # I will use this to confirm the row has baseline data\n",
    "    'surv_lang_0m',      # Language of survey,\n",
    "    \n",
    "    # --- B. Baseline Health Need & Utilization ---\n",
    "\n",
    "    'needmet_med_0m',    # [1/0] Did they get *all* the care they needed? (Captures unmet need)\n",
    "    'needmet_rx_0m',     # [1/0] Did they get *all* the medication they needed? (Captures unmet need)\n",
    "\n",
    "    'rx_num_mod_0m',     # [Num] How many *different* prescription drugs? (Measures chronic need)\n",
    "    'doc_num_mod_0m',    # [Num] Number of doctor visits in last 6 mos (Measures utilization)\n",
    "    'er_num_mod_0m',     # [Num] Number of ER visits in last 6 mos (Measures high-cost shocks)\n",
    "    'hosp_num_mod_0m',   # [Num] Number of hospitalizations in last 6 mos (Measures high-cost shocks)\n",
    "    'need_rx_0m',        # [1/0] Did they have all medication needed\n",
    "    'need_med_0m',       # [1/0] Did they have all treatment needed\n",
    "    \n",
    "    'ins_months_0m',     # [Num] How many of the last 6 mos were they insured? (A key eligibility/need var)\n",
    "    \n",
    "    # --- C. Baseline Health Status ---\n",
    "    'health_gen_0m',     # [1-5] Overall health (Excellent, Good, Fair, Poor)\n",
    "    'baddays_phys_0m',   # [0-30] Num days physical health was \"not good\"\n",
    "    'baddays_ment_0m',   # [0-30] Num days mental health was \"not good\"\n",
    "    'health_chg_0m',     # [1-3] Health trajectory (Better, Same, Worse)\n",
    "\n",
    "    # --- D. Baseline Diagnosed Conditions ---\n",
    "    'dia_dx_0m',         # [1/0] Diagnosed with Diabetes\n",
    "    'ast_dx_0m',         # [1/0] Diagnosed with Asthma\n",
    "    'hbp_dx_0m',         # [1/0] Diagnosed with High Blood Pressure\n",
    "    'emp_dx_0m',         # [1/0] Diagnosed with Emphysema/COPD\n",
    "    'chf_dx_0m',         # [1/0] Diagnosed with Congestive Heart Failure\n",
    "    'dep_dx_0m',         # [1/0] Diagnosed with Depression/Anxiety\n",
    "\n",
    "    # --- E. Baseline Demographics ---\n",
    "    'female_0m',         # [1/0] Gender variable\n",
    "    'birthyear_0m',      # [Year] I will use this to calculate baseline age\n",
    "    'edu_0m',            # [Cat] Highest level of education\n",
    "    \n",
    "    # --- F. Baseline Race & Ethnicity ---\n",
    "    'race_hisp_0m',      # [1/0] Hispanic\n",
    "    'race_white_0m',     # [1/0] White\n",
    "    'race_black_0m',     # [1/0] Black\n",
    "    'race_amerindian_0m',# [1/0] American Indian/Alaska Native\n",
    "    'race_asian_0m',     # [1/0] Asian\n",
    "    'race_pacific_0m',   # [1/0] Native Hawaiian/Pacific Islander\n",
    "    'race_other_qn_0m',  # [1/0] Other race\n",
    "    \n",
    "    # --- G. Baseline Employment & Household ---\n",
    "    'employ_0m',         # [0/1] Employed \n",
    "    'employ_hrs_0m',     # [Cat] Hours worked per week (Note: Corrected from 'emply_hrs_qn_0m')\n",
    "    'hhinc_cat_0m',      # [Cat] Household income category (CRITICAL covariate)\n",
    "    'hhsize_0m',         # [Num] Household size\n",
    "    'num19_0m',          # [Num] Number of children under 19 in household\n",
    "    \n",
    "    # --- H. Baseline Financial Status ---  \n",
    "    'cost_any_oop_0m',        # [1/0] Any out of pocket costs for medical care\n",
    "    'cost_borrow_0m',         # [1/0] Borrowed money/skipped bills to pay health care bills\n",
    "    'cost_any_owe_0m',        # [1/0] Currently owe money for medical expenses\n",
    "    'cost_tot_owe_0m',        # [Num] Total amount currently owed for medical expenses\n",
    "    'cost_refused_0m',        # [1/0] Have you been refused care because you owed money for a past treatment?\n",
    "    'cost_tot_oop_correct_0m' # [Num] Total *corrected* out-of-pocket spending\n",
    "]\n",
    "\n",
    "df_X_path = data_dir / \"oregonhie_survey0m_vars.dta\"\n",
    "df_X = pd.read_stata(\n",
    "    df_X_path,\n",
    "    columns=col_keep_X,\n",
    "    convert_categoricals=False,\n",
    "    preserve_dtypes=True\n",
    ")\n",
    "if df_X[\"person_id\"].isna().any():\n",
    "    raise ValueError(\"df_X has missing person_id values.\")\n",
    "\n",
    "df_X[\"person_id\"] = df_X[\"person_id\"].astype(\"int64\")\n",
    "\n",
    "print(\"df_X shape:\", df_X.shape)\n",
    "df_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e9ce00-2a64-4fd9-9ad3-0bf33477746b",
   "metadata": {},
   "source": [
    "### Part 3: Instrument Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98d21116-7e43-43dd-8f50-33976f031056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_IV shape: (74922, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>household_id</th>\n",
       "      <th>treatment</th>\n",
       "      <th>numhh_list</th>\n",
       "      <th>zip_msa_list</th>\n",
       "      <th>female_list</th>\n",
       "      <th>birthyear_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>100005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_id  household_id  treatment  numhh_list  zip_msa_list  female_list  birthyear_list\n",
       "0          1        100001          1           1           1.0          0.0            1978\n",
       "1          2        100002          1           1           1.0          1.0            1984\n",
       "2          3        100003          0           1           1.0          1.0            1971\n",
       "3          4        100004          0           1           1.0          1.0            1955\n",
       "4          5        100005          1           1           1.0          1.0            1969"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For descriptive data\n",
    "# To pull instrument mainly\n",
    "col_keep_IV = [\n",
    "    # --- A. Key & Instrument Variables ---\n",
    "    'person_id',         # The unique ID to merge all files\n",
    "    'household_id',      # The unique household ID\n",
    "    'treatment',         # [1/0] This is the Instrument (Z)\n",
    "    \n",
    "    # --- B. Critical Control Variable ---\n",
    "    'numhh_list',        # [Num] Number of people in the household on the lottery list.\n",
    "                         \n",
    "    # --- C. Baseline Demographics (from lottery list) --- collected before the lottery\n",
    "    'zip_msa_list',      # [1/0] Is the zip code in a Metropolitan Statistical Area (urban vs. rural)\n",
    "    'female_list',       # [1/0] Gender from lottery sign-up card (backup)\n",
    "    'birthyear_list',    # [Year] Birth year from lottery sign-up card (backup)               \n",
    "]\n",
    "\n",
    "df_IV_path = data_dir / \"oregonhie_descriptive_vars.dta\"\n",
    "df_IV = pd.read_stata(\n",
    "    df_IV_path,\n",
    "    columns=col_keep_IV,\n",
    "    convert_categoricals=False,\n",
    "    preserve_dtypes=True\n",
    ")\n",
    "if df_IV[\"person_id\"].isna().any():\n",
    "    raise ValueError(\"df_IV has missing person_id values.\")\n",
    "if df_IV[\"household_id\"].isna().any():\n",
    "    raise ValueError(\"df_IV has missing household_id values.\")\n",
    "\n",
    "df_IV[\"person_id\"] = df_IV[\"person_id\"].astype(\"int64\")\n",
    "df_IV[\"household_id\"] = df_IV[\"household_id\"].astype(\"int64\")\n",
    "\n",
    "print(\"df_IV shape:\", df_IV.shape)\n",
    "df_IV.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f875a52-a006-4099-ba2f-355539b327fc",
   "metadata": {},
   "source": [
    "### Part 4: Treatment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f774632-eb89-4c77-8e48-ae483f231d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_W shape: (74922, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>ohp_all_ever_firstn_30sep2009</th>\n",
       "      <th>ohp_all_mo_firstn_30sep2009</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_id  ohp_all_ever_firstn_30sep2009  ohp_all_mo_firstn_30sep2009\n",
       "0          1                              0                            0\n",
       "1          2                              1                           12\n",
       "2          3                              0                            0\n",
       "3          4                              1                           18\n",
       "4          5                              0                            0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For state program data\n",
    "# To pull treatment\n",
    "col_keep_W = [\n",
    "    # --- A. Key & Treatment Variables ---\n",
    "    'person_id',                       # The unique ID to merge all files\n",
    "    \n",
    "    'ohp_all_ever_firstn_30sep2009',    # [1/0] This is Treatment (W).\n",
    "                                       # The codebook confirms this is the correct\n",
    "                                       # \"ever enrolled in Medicaid\" variable to use\n",
    "    'ohp_all_mo_firstn_30sep2009'      # continuous treatment intensity\n",
    "\n",
    "]\n",
    "\n",
    "df_W_path = data_dir / \"oregonhie_stateprograms_vars.dta\"\n",
    "df_W = pd.read_stata(\n",
    "    df_W_path,\n",
    "    columns=col_keep_W,\n",
    "    convert_categoricals=False,\n",
    "    preserve_dtypes=True\n",
    ")\n",
    "if df_W[\"person_id\"].isna().any():\n",
    "    raise ValueError(\"df_W has missing person_id values.\")\n",
    "\n",
    "df_W[\"person_id\"] = df_W[\"person_id\"].astype(\"int64\")\n",
    "\n",
    "print(\"df_W shape:\", df_W.shape)\n",
    "df_W.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b1d4b2-2e17-4676-afd2-8e8d6f143c2c",
   "metadata": {},
   "source": [
    "### Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0298c69b-45e7-4d6f-9cbd-7186fde2b493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outcomes (df_y): 74,922 rows × 16 cols\n",
      "  - ID type: int64\n",
      "  - Unique IDs: 74,922\n",
      "\n",
      "Covariates (df_X): 74,922 rows × 43 cols\n",
      "  - ID type: int64\n",
      "  - Unique IDs: 74,922\n",
      "\n",
      "IV/Lottery (df_IV): 74,922 rows × 7 cols\n",
      "  - ID type: int64\n",
      "  - Unique IDs: 74,922\n",
      "\n",
      "Treatment (df_W): 74,922 rows × 3 cols\n",
      "  - ID type: int64\n",
      "  - Unique IDs: 74,922\n",
      "\n",
      "Common IDs across all four files: 74,922 individuals\n",
      "  (Intersection of all person_id sets)\n",
      "  - Present in outcomes: 74,922 (lost 0 when intersecting all files)\n",
      "  - Present in covariates: 74,922 (lost 0 when intersecting all files)\n",
      "  - Present in IV: 74,922 (lost 0 when intersecting all files)\n",
      "  - Present in treatment: 74,922 (lost 0 when intersecting all files)\n"
     ]
    }
   ],
   "source": [
    "def validate_df(df, name):\n",
    "    print(f\"\\n{name}: {df.shape[0]:,} rows × {df.shape[1]} cols\")\n",
    "    \n",
    "    missing = df['person_id'].isna().sum()\n",
    "    if missing > 0:\n",
    "        raise ValueError(f\"{name} has {missing} missing person_id values\")\n",
    "    \n",
    "    dups = df['person_id'].duplicated().sum()\n",
    "    if dups > 0:\n",
    "        raise ValueError(f\"{name} has {dups} duplicate person_id values\")\n",
    "    \n",
    "    print(f\"  - ID type: {df['person_id'].dtype}\")\n",
    "    print(f\"  - Unique IDs: {df['person_id'].nunique():,}\")\n",
    "\n",
    "# Run validation on all datasets\n",
    "validate_df(df_y, \"Outcomes (df_y)\")\n",
    "validate_df(df_X, \"Covariates (df_X)\")\n",
    "validate_df(df_IV, \"IV/Lottery (df_IV)\")\n",
    "validate_df(df_W, \"Treatment (df_W)\")\n",
    "\n",
    "pid_sets = {\n",
    "    'outcomes': set(df_y['person_id']),\n",
    "    'covariates': set(df_X['person_id']),\n",
    "    'IV': set(df_IV['person_id']),\n",
    "    'treatment': set(df_W['person_id'])\n",
    "}\n",
    "\n",
    "common_ids_all_files = set.intersection(*pid_sets.values())\n",
    "print(f\"\\nCommon IDs across all four files: {len(common_ids_all_files):,} individuals\")\n",
    "print(\"  (Intersection of all person_id sets)\")\n",
    "\n",
    "for name, pid_set in pid_sets.items():\n",
    "    loss = len(pid_set - common_ids_all_files)\n",
    "    print(f\"  - Present in {name}: {len(pid_set):,} (lost {loss:,} when intersecting all files)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef18f927-d799-46e0-ad00-bdac29d02a3e",
   "metadata": {},
   "source": [
    "# Merging Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69f642f9-55b5-402e-8050-63c1fda0ad68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merge: 74,922 rows × 66 columns\n"
     ]
    }
   ],
   "source": [
    "# start with universe (IV), safe for attrition analysis and errors out if person_id is not 1:1\n",
    "df_merged = (df_IV\n",
    "             .merge(df_X, on=\"person_id\", how=\"left\", validate=\"1:1\")\n",
    "             .merge(df_y, on=\"person_id\", how=\"left\", validate=\"1:1\")\n",
    "             .merge(df_W, on=\"person_id\", how=\"left\", validate=\"1:1\")\n",
    "            )\n",
    "\n",
    "print(f\"After merge: {df_merged.shape[0]:,} rows × {df_merged.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee313ac-4c7c-45da-87ac-58225fa75f81",
   "metadata": {},
   "source": [
    "### Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed46dae-b3de-4400-a51d-06ff0993751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To alighn with Econometric Standard (Z, W)\n",
    "rename_map = {\n",
    "    'treatment': 'Z_lottery',                     # The Instrument\n",
    "    'ohp_all_ever_firstn_30sep2009': 'W_medicaid' # The Treatment\n",
    "}\n",
    "\n",
    "df_merged.rename(columns=rename_map, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c002db-b624-4fbf-aa5a-c4b7941c25f6",
   "metadata": {},
   "source": [
    "# Attrition Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e083d7f-554b-4c23-8be9-b29e8733b830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATTRITION SUMMARY BY LOTTERY STATUS (within 12m survey frame)\n",
      "======================================================================\n",
      " Z_lottery  N_Total  N_Responded  Response_Rate\n",
      "         0    28816        11966         41.526\n",
      "         1    29589        11811         39.917\n",
      "\n",
      "Difference in response rate (Z=1 minus Z=0): -1.61 percentage points\n",
      "Cluster-robust p-value for Z_lottery: 0.0003\n",
      "p-value = 0.0002814 < 0.05\n",
      "⇒ Overall 12m response differs significantly by lottery status.\n"
     ]
    }
   ],
   "source": [
    "# If some rows have missing Z_lottery, drop them for these diagnostics\n",
    "mask_Z = df_merged['Z_lottery'].isin([0, 1])\n",
    "df_attr = df_merged.loc[mask_Z].copy()\n",
    "\n",
    "# Define responded indicator: 1 if 12m survey returned, 0 otherwise\n",
    "df_attr['responded'] = (df_attr['returned_12m'] == 1).astype(int)\n",
    "\n",
    "df_attr['in_12m_sample'] = df_attr['returned_12m'].notna().astype(int)\n",
    "df_attr_12m = df_attr[df_attr['in_12m_sample'] == 1].copy()\n",
    "\n",
    "# Overall attrition by lottery status with cluster-robust test\n",
    "attrition_summary = (\n",
    "    df_attr_12m\n",
    "    .groupby('Z_lottery')['responded']\n",
    "    .agg(N_Total='count',\n",
    "         N_Responded='sum',\n",
    "         Response_Rate=lambda x: 100 * x.mean())\n",
    "    .reset_index())\n",
    "\n",
    "# Ensure clean formatting\n",
    "attrition_summary['N_Total'] = attrition_summary['N_Total'].astype(int)\n",
    "attrition_summary['N_Responded'] = attrition_summary['N_Responded'].astype(int)\n",
    "attrition_summary['Response_Rate'] = attrition_summary['Response_Rate'].round(3)\n",
    "\n",
    "print(\"ATTRITION SUMMARY BY LOTTERY STATUS (within 12m survey frame)\")\n",
    "print(\"=\"*70)\n",
    "print(attrition_summary.to_string(index=False))\n",
    "\n",
    "# Cluster-robust LPM: responded ~ Z_lottery\n",
    "attrition_model = smf.ols('responded ~ Z_lottery', data=df_attr_12m).fit(\n",
    "    cov_type='cluster',\n",
    "    cov_kwds={'groups': df_attr_12m['household_id']})\n",
    "\n",
    "diff_pp = (attrition_summary.loc[attrition_summary['Z_lottery'] == 1, 'Response_Rate'].iloc[0]\n",
    "         - attrition_summary.loc[attrition_summary['Z_lottery'] == 0, 'Response_Rate'].iloc[0])\n",
    "\n",
    "print(f\"\\nDifference in response rate (Z=1 minus Z=0): {diff_pp:+.2f} percentage points\")\n",
    "print(f\"Cluster-robust p-value for Z_lottery: {attrition_model.pvalues['Z_lottery']:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "p_val = attrition_model.pvalues['Z_lottery']\n",
    "if p_val < alpha:\n",
    "    print(f\"p-value = {p_val:.4g} < {alpha}\")\n",
    "    print(\"⇒ Overall 12m response differs significantly by lottery status.\")\n",
    "else:\n",
    "    print(f\"p-value = {p_val:.4g} ≥ {alpha}\")\n",
    "    print(\"⇒ No statistically significant difference in overall 12m response by lottery status.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ebc3a17-f1e3-41d0-bba2-a0752f8c2d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_Z0_attriters (N=16,850)</th>\n",
       "      <th>Mean_Z1_attriters (N=17,778)</th>\n",
       "      <th>Raw_diff_Z1_minus_Z0</th>\n",
       "      <th>Std_diff_Z1_minus_Z0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>birthyear_0m</th>\n",
       "      <td>1967.894</td>\n",
       "      <td>1968.447</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_0m</th>\n",
       "      <td>0.534</td>\n",
       "      <td>0.529</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_gen_0m</th>\n",
       "      <td>2.805</td>\n",
       "      <td>2.813</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hhinc_cat_0m</th>\n",
       "      <td>6.058</td>\n",
       "      <td>6.315</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_any_owe_0m</th>\n",
       "      <td>0.676</td>\n",
       "      <td>0.654</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Mean_Z0_attriters (N=16,850)  Mean_Z1_attriters (N=17,778)  Raw_diff_Z1_minus_Z0  Std_diff_Z1_minus_Z0\n",
       "birthyear_0m                         1967.894                      1968.447                 0.553                 0.046\n",
       "female_0m                               0.534                         0.529                -0.005                -0.009\n",
       "health_gen_0m                           2.805                         2.813                 0.008                 0.007\n",
       "hhinc_cat_0m                            6.058                         6.315                 0.258                 0.057\n",
       "cost_any_owe_0m                         0.676                         0.654                -0.021                -0.045"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rule of thumb: |Std_diff| > 0.1 indicates non-trivial imbalance.\n"
     ]
    }
   ],
   "source": [
    "# Define 12m sample indicator and attriters among that sample\n",
    "attriters = df_attr_12m[df_attr_12m['responded'] == 0]\n",
    "\n",
    "attriters_Z0 = attriters[attriters['Z_lottery'] == 0]\n",
    "attriters_Z1 = attriters[attriters['Z_lottery'] == 1]\n",
    "\n",
    "# testing for a subset of covariates: demographic, medical, financial\n",
    "balance_vars = ['birthyear_0m', 'female_0m', 'health_gen_0m', 'hhinc_cat_0m', 'cost_any_owe_0m']\n",
    "means_Z0 = attriters_Z0[balance_vars].mean()\n",
    "means_Z1 = attriters_Z1[balance_vars].mean()\n",
    "vars_Z0 = attriters_Z0[balance_vars].var()\n",
    "vars_Z1 = attriters_Z1[balance_vars].var()\n",
    "sd_pooled = np.sqrt(0.5 * vars_Z0 + 0.5 * vars_Z1)\n",
    "std_diff = (means_Z1 - means_Z0) / sd_pooled\n",
    "attriter_balance = pd.DataFrame({\n",
    "    'Mean_Z0_attriters': means_Z0,\n",
    "    'Mean_Z1_attriters': means_Z1,\n",
    "    'Raw_diff_Z1_minus_Z0': means_Z1 - means_Z0,\n",
    "    'Std_diff_Z1_minus_Z0': std_diff}).round(3)\n",
    "col_Z0 = f\"Mean_Z0_attriters (N={len(attriters_Z0):,})\"\n",
    "col_Z1 = f\"Mean_Z1_attriters (N={len(attriters_Z1):,})\"\n",
    "attriter_balance = attriter_balance.rename(columns={\n",
    "    'Mean_Z0_attriters': col_Z0,\n",
    "    'Mean_Z1_attriters': col_Z1})\n",
    "display(attriter_balance)\n",
    "print(\"\\nRule of thumb: |Std_diff| > 0.1 indicates non-trivial imbalance.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bd196dc-bb5a-4377-b9d4-7a3b6cd9e9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Sample  Z=0 enrollment rate  Z=1 enrollment rate\n",
      "Full randomized sample                0.146                0.395\n",
      "   12m responders only                0.134                0.428\n",
      "\n",
      "First-stage F-statistics (cluster-robust):\n",
      "  Full sample:     F = 5006.46, p = 0\n",
      "  12m responders:  F = 2492.75, p = 0\n"
     ]
    }
   ],
   "source": [
    "# Restrict to units with observed W_medicaid\n",
    "mask_W = df_attr['W_medicaid'].notna()\n",
    "df_fs_full = df_attr.loc[mask_W].copy()\n",
    "df_fs_resp = df_attr.loc[mask_W & (df_attr['returned_12m'] == 1)].copy()\n",
    "fs_rates_full = df_fs_full.groupby('Z_lottery')['W_medicaid'].mean()\n",
    "fs_rates_resp = df_fs_resp.groupby('Z_lottery')['W_medicaid'].mean()\n",
    "fs_table = pd.DataFrame({\n",
    "    'Sample': ['Full randomized sample', '12m responders only'],\n",
    "    'Z=0 enrollment rate': [fs_rates_full.get(0, np.nan), fs_rates_resp.get(0, np.nan)],\n",
    "    'Z=1 enrollment rate': [fs_rates_full.get(1, np.nan), fs_rates_resp.get(1, np.nan)]}).round(3)\n",
    "print(fs_table.to_string(index=False))\n",
    "\n",
    "# First-stage regressions with household clustering\n",
    "fs_model_full = smf.ols('W_medicaid ~ Z_lottery', data=df_fs_full).fit(\n",
    "    cov_type='cluster',\n",
    "    cov_kwds={'groups': df_fs_full['household_id']})\n",
    "fs_model_resp = smf.ols('W_medicaid ~ Z_lottery', data=df_fs_resp).fit(\n",
    "    cov_type='cluster',\n",
    "    cov_kwds={'groups': df_fs_resp['household_id']})\n",
    "\n",
    "print(\"\\nFirst-stage F-statistics (cluster-robust):\")\n",
    "print(f\"  Full sample:     F = {fs_model_full.fvalue:.2f}, p = {fs_model_full.f_pvalue:.4g}\")\n",
    "print(f\"  12m responders:  F = {fs_model_resp.fvalue:.2f}, p = {fs_model_resp.f_pvalue:.4g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c58e1ceb-e420-4759-afca-81234ec40827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted 12m response rate: 40.711%\n",
      "Weighted 12m response rate:   50.039%\n",
      "Difference (weighted - unweighted): +9.328%\n"
     ]
    }
   ],
   "source": [
    "# Only units in the 12m survey file have weight_12m\n",
    "mask_weight = df_attr['weight_12m'].notna()\n",
    "df_weight = df_attr.loc[mask_weight].copy()\n",
    "\n",
    "unweighted_rate = (df_weight['returned_12m'] == 1).mean()\n",
    "weighted_rate = np.average(\n",
    "    (df_weight['returned_12m'] == 1).astype(int),\n",
    "    weights=df_weight['weight_12m'])\n",
    "\n",
    "print(f\"Unweighted 12m response rate: {unweighted_rate:.3%}\")\n",
    "print(f\"Weighted 12m response rate:   {weighted_rate:.3%}\")\n",
    "print(f\"Difference (weighted - unweighted): {weighted_rate - unweighted_rate:+.3%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a495e236-7a95-4256-a94c-6fc8d1fb556d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differential attrition is modest (≈ -1.6 pp).\n",
      "Max standardized difference among attriters: 0.057\n",
      "Attriter baseline balance looks acceptable (all |StdDiff| ≤ 0.1).\n"
     ]
    }
   ],
   "source": [
    "if abs(diff_pp) > 2.0:\n",
    "    print(f\"Differential attrition is larger than 2pp (|{diff_pp:.1f}| > 2).\")\n",
    "else:\n",
    "    print(f\"Differential attrition is modest (≈ {diff_pp:.1f} pp).\")\n",
    "\n",
    "max_std_diff = attriter_balance['Std_diff_Z1_minus_Z0'].abs().max()\n",
    "print(f\"Max standardized difference among attriters: {max_std_diff:.3f}\")\n",
    "if max_std_diff > 0.1:\n",
    "    print(\"Some baseline variables among attriters show |StdDiff| > 0.1.\")\n",
    "else:\n",
    "    print(\"Attriter baseline balance looks acceptable (all |StdDiff| ≤ 0.1).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e947eeac-47ee-495e-9a66-095ca3ab6a74",
   "metadata": {},
   "source": [
    "# Analysis Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a959f5d6-cd4b-440c-88f2-8723cdef2d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis sample (responded to 0m and 12m): 16,579 rows × 66 columns\n"
     ]
    }
   ],
   "source": [
    "# Keep only individuals who answered BOTH baseline (0m) and 12m surveys\n",
    "df_analysis_sample = df_merged.loc[\n",
    "    (df_merged[\"returned_0m\"] == 1) &\n",
    "    (df_merged[\"returned_12m\"] == 1)\n",
    "].copy()\n",
    "\n",
    "print(f\"Analysis sample (responded to 0m and 12m): \"\n",
    "      f\"{df_analysis_sample.shape[0]:,} rows × {df_analysis_sample.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95e7f36a-b710-42d9-b73a-d713f920eb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_lottery\n",
      "0    8432\n",
      "1    8147\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "W_medicaid\n",
      "0    11818\n",
      "1     4761\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Missing values:\n",
      "Z_lottery:  0\n",
      "W_medicaid: 0\n"
     ]
    }
   ],
   "source": [
    "# Distribution of instrument (Z) and treatment (W) in the analysis sample\n",
    "print(df_analysis_sample[\"Z_lottery\"].value_counts(dropna=False), \"\\n\")\n",
    "\n",
    "print(df_analysis_sample[\"W_medicaid\"].value_counts(dropna=False), \"\\n\")\n",
    "\n",
    "# Explicitly confirm no missing values in Z or W\n",
    "print(\"Missing values:\")\n",
    "print(\"Z_lottery: \", df_analysis_sample[\"Z_lottery\"].isna().sum())\n",
    "print(\"W_medicaid:\", df_analysis_sample[\"W_medicaid\"].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a504dc8-4ce6-419e-a855-c02e9c6f22c4",
   "metadata": {},
   "source": [
    "# Balance Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04e11fd4-afe5-4f4a-9c5f-a5e69913ee90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_Z0</th>\n",
       "      <th>Mean_Z1</th>\n",
       "      <th>Raw_diff_Z1_minus_Z0</th>\n",
       "      <th>Std_diff_Z1_minus_Z0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>birthyear_0m</th>\n",
       "      <td>1,964.69</td>\n",
       "      <td>1,965.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_0m</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_gen_0m</th>\n",
       "      <td>2.75</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baddays_phys_0m</th>\n",
       "      <td>9.67</td>\n",
       "      <td>9.08</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baddays_ment_0m</th>\n",
       "      <td>11.24</td>\n",
       "      <td>10.41</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dia_dx_0m</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ast_dx_0m</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hbp_dx_0m</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emp_dx_0m</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chf_dx_0m</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dep_dx_0m</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hhinc_cat_0m</th>\n",
       "      <td>6.19</td>\n",
       "      <td>6.60</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hhsize_0m</th>\n",
       "      <td>2.96</td>\n",
       "      <td>627.51</td>\n",
       "      <td>624.55</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num19_0m</th>\n",
       "      <td>1.08</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_any_owe_0m</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_tot_owe_0m</th>\n",
       "      <td>2,613,360.25</td>\n",
       "      <td>3,449,706.50</td>\n",
       "      <td>836,346.25</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_any_oop_0m</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ins_months_0m</th>\n",
       "      <td>0.95</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip_msa_list</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numhh_list</th>\n",
       "      <td>1.25</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Mean_Z0      Mean_Z1  Raw_diff_Z1_minus_Z0  Std_diff_Z1_minus_Z0\n",
       "birthyear_0m        1,964.69     1,965.00                  0.31                  0.03\n",
       "female_0m               0.60         0.57                 -0.03                 -0.05\n",
       "health_gen_0m           2.75         2.83                  0.07                  0.07\n",
       "baddays_phys_0m         9.67         9.08                 -0.59                 -0.05\n",
       "baddays_ment_0m        11.24        10.41                 -0.83                 -0.07\n",
       "dia_dx_0m               0.12         0.11                 -0.01                 -0.04\n",
       "ast_dx_0m               0.16         0.15                 -0.01                 -0.04\n",
       "hbp_dx_0m               0.29         0.27                 -0.02                 -0.05\n",
       "emp_dx_0m               0.08         0.07                 -0.01                 -0.03\n",
       "chf_dx_0m               0.03         0.03                 -0.00                 -0.01\n",
       "dep_dx_0m               0.44         0.40                 -0.04                 -0.08\n",
       "hhinc_cat_0m            6.19         6.60                  0.41                  0.09\n",
       "hhsize_0m               2.96       627.51                624.55                  0.02\n",
       "num19_0m                1.08         0.94                 -0.14                 -0.01\n",
       "cost_any_owe_0m         0.61         0.59                 -0.03                 -0.05\n",
       "cost_tot_owe_0m 2,613,360.25 3,449,706.50            836,346.25                  0.02\n",
       "cost_any_oop_0m         0.69         0.68                 -0.02                 -0.03\n",
       "ins_months_0m           0.95         1.15                  0.20                  0.10\n",
       "zip_msa_list            0.74         0.74                 -0.00                 -0.00\n",
       "numhh_list              1.25         1.34                  0.10                  0.21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rule of thumb: |Std_diff| > 0.1 indicates non-trivial imbalance.\n",
      "\n",
      "Max standardized difference in analysis sample: 0.209\n"
     ]
    }
   ],
   "source": [
    "# Choose a set of key pre-treatment covariates:\n",
    "#   - demographics\n",
    "#   - baseline health\n",
    "#   - baseline financial situation\n",
    "#   - pre-lottery list info\n",
    "balance_vars = [\n",
    "    'birthyear_0m',    # age proxy (you can later switch to age_0m once you construct it)\n",
    "    'female_0m',\n",
    "    'health_gen_0m',\n",
    "    'baddays_phys_0m',\n",
    "    'baddays_ment_0m',\n",
    "    'dia_dx_0m', 'ast_dx_0m', 'hbp_dx_0m', 'emp_dx_0m', 'chf_dx_0m', 'dep_dx_0m',\n",
    "    'hhinc_cat_0m',\n",
    "    'hhsize_0m',\n",
    "    'num19_0m',\n",
    "    'cost_any_owe_0m',\n",
    "    'cost_tot_owe_0m',\n",
    "    'cost_any_oop_0m',\n",
    "    'ins_months_0m',\n",
    "    'zip_msa_list',    # pre-lottery MSA indicator\n",
    "    'numhh_list'       # household size on lottery list (pre-randomization)\n",
    "]\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "# Some vars might be missing in rare cases; keep only those present in the DataFrame\n",
    "balance_vars = [v for v in balance_vars if v in df_analysis_sample.columns]\n",
    "\n",
    "means_Z0 = df_analysis_sample.loc[df_analysis_sample['Z_lottery'] == 0, balance_vars].mean()\n",
    "means_Z1 = df_analysis_sample.loc[df_analysis_sample['Z_lottery'] == 1, balance_vars].mean()\n",
    "\n",
    "vars_Z0 = df_analysis_sample.loc[df_analysis_sample['Z_lottery'] == 0, balance_vars].var()\n",
    "vars_Z1 = df_analysis_sample.loc[df_analysis_sample['Z_lottery'] == 1, balance_vars].var()\n",
    "\n",
    "sd_pooled = np.sqrt(0.5 * vars_Z0 + 0.5 * vars_Z1)\n",
    "std_diff = (means_Z1 - means_Z0) / sd_pooled\n",
    "\n",
    "balance_table = pd.DataFrame({\n",
    "    'Mean_Z0': means_Z0,\n",
    "    'Mean_Z1': means_Z1,\n",
    "    'Raw_diff_Z1_minus_Z0': means_Z1 - means_Z0,\n",
    "    'Std_diff_Z1_minus_Z0': std_diff\n",
    "}).round(3)\n",
    "\n",
    "display(balance_table)\n",
    "print(\"\\nRule of thumb: |Std_diff| > 0.1 indicates non-trivial imbalance.\")\n",
    "\n",
    "max_std_diff = balance_table['Std_diff_Z1_minus_Z0'].abs().max()\n",
    "print(f\"\\nMax standardized difference in analysis sample: {max_std_diff:.3f}\")\n",
    "# here cost_tot_owe_0m will later be taken in log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee1dd26-5a99-4892-aa44-12d39795299c",
   "metadata": {},
   "source": [
    "# Check Instrument Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ce9d076-acb5-415d-841b-78b847c36931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Joint distribution of (Z, W) in analysis sample:\n",
      "W_medicaid      0     1    All\n",
      "Z_lottery                     \n",
      "0            7328  1104   8432\n",
      "1            4490  3657   8147\n",
      "All         11818  4761  16579\n",
      "\n",
      "Observed compliance patterns (counts):\n",
      "  Always-takers (Z=0, W=1): 1,104\n",
      "  Never-takers  (Z=1, W=0): 4,490\n",
      "  Interpretation as always-/never-takers relies on the monotonicity assumption (no defiers).\n",
      "\n",
      "Enrollment rates by lottery status in analysis sample:\n",
      "  Enrollment rate (Z=1, won):  44.9% (n=8,147)\n",
      "  Enrollment rate (Z=0, lost): 13.1% (n=8,432)\n",
      "  ITT effect Z → W (compliance rate): +31.8% points\n",
      "\n",
      "Raw first stage (diagnostic, no controls):\n",
      "  Coefficient on Z_lottery: 0.3179\n",
      "  Robust SE:                0.0071\n",
      "  Robust F-statistic:       2021.84\n",
      "  Robust p-value:           0\n",
      "\n",
      "Strong first stage (robust F = 2021.8 ≥ 10).\n",
      "\n",
      "Adjusted first stage (with numhh_list control):\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.2217      0.011     20.660      0.000       0.201       0.243\n",
      "Z_lottery      0.3249      0.007     46.270      0.000       0.311       0.339\n",
      "numhh_list    -0.0729      0.008     -8.833      0.000      -0.089      -0.057\n",
      "==============================================================================\n",
      "\n",
      "Cluster-robust F-stat for Z_lottery (conditional): 2140.92 (p = 0)\n",
      "Cluster-robust t-stat for Z_lottery:                 46.27\n"
     ]
    }
   ],
   "source": [
    "# Compliance patterns (raw counts)\n",
    "compliance_tab = pd.crosstab(df_analysis_sample[\"Z_lottery\"],\n",
    "                             df_analysis_sample[\"W_medicaid\"], \n",
    "                             margins=True)\n",
    "print(\"\\nJoint distribution of (Z, W) in analysis sample:\")\n",
    "print(compliance_tab)\n",
    "\n",
    "always_takers = compliance_tab.loc[0, 1] # Z=0, W=1\n",
    "never_takers = compliance_tab.loc[1, 0] # Z=1, W=0\n",
    "\n",
    "print(\"\\nObserved compliance patterns (counts):\")\n",
    "print(f\"  Always-takers (Z=0, W=1): {always_takers:,}\")\n",
    "print(f\"  Never-takers  (Z=1, W=0): {never_takers:,}\")\n",
    "print(\"  Interpretation as always-/never-takers relies on the monotonicity assumption (no defiers).\")\n",
    "\n",
    "# ITT on W (first-stage mean difference)\n",
    "enrollment_means = df_analysis_sample.groupby(\"Z_lottery\")[\"W_medicaid\"].mean()\n",
    "mean_lost = enrollment_means.loc[0]\n",
    "mean_won = enrollment_means.loc[1]\n",
    "compliance_rate = mean_won - mean_lost\n",
    "\n",
    "print(\"\\nEnrollment rates by lottery status in analysis sample:\")\n",
    "print(f\"  Enrollment rate (Z=1, won):  {mean_won:.1%} (n={compliance_tab.loc[1, 'All']:,})\")\n",
    "print(f\"  Enrollment rate (Z=0, lost): {mean_lost:.1%} (n={compliance_tab.loc[0, 'All']:,})\")\n",
    "print(f\"  ITT effect Z → W (compliance rate): {compliance_rate:+.1%} points\")\n",
    "\n",
    "# RAW first stage (for weak instrument diagnostic)\n",
    "fs_raw = smf.ols('W_medicaid ~ Z_lottery', data=df_analysis_sample).fit(cov_type='cluster',\n",
    "                                                cov_kwds={'groups': df_analysis_sample['household_id']})\n",
    "fs_raw_test = fs_raw.f_test(\"Z_lottery = 0\")\n",
    "F_raw = float(fs_raw_test.fvalue)\n",
    "p_raw = float(fs_raw_test.pvalue)\n",
    "\n",
    "print(\"\\nRaw first stage (diagnostic, no controls):\")\n",
    "print(f\"  Coefficient on Z_lottery: {fs_raw.params['Z_lottery']:.4f}\")\n",
    "print(f\"  Robust SE:                {fs_raw.bse['Z_lottery']:.4f}\")\n",
    "print(f\"  Robust F-statistic:       {F_raw:.2f}\")\n",
    "print(f\"  Robust p-value:           {p_raw:.4g}\")\n",
    "\n",
    "F_THRESHOLD = 10\n",
    "if F_raw < F_THRESHOLD:\n",
    "    print(f\"\\nWeak first stage (robust F = {F_raw:.1f} < {F_THRESHOLD}).\")\n",
    "else:\n",
    "    print(f\"\\nStrong first stage (robust F = {F_raw:.1f} ≥ {F_THRESHOLD}).\")\n",
    "\n",
    "# Conditional first stage WITH numhh_list (for estimation)\n",
    "fs_data = df_analysis_sample.dropna(subset=['W_medicaid', 'Z_lottery', 'numhh_list', 'household_id'])\n",
    "\n",
    "fs_adj = smf.ols('W_medicaid ~ Z_lottery + numhh_list', data=fs_data).fit(cov_type='cluster',\n",
    "                                                    cov_kwds={'groups': fs_data['household_id']})\n",
    "\n",
    "print(\"\\nAdjusted first stage (with numhh_list control):\")\n",
    "print(fs_adj.summary().tables[1].as_text())\n",
    "\n",
    "fs_test = fs_adj.f_test(\"Z_lottery = 0\")\n",
    "f_statistic = float(fs_test.fvalue)\n",
    "p_f = float(fs_test.pvalue)\n",
    "t_statistic = fs_adj.tvalues[\"Z_lottery\"]\n",
    "\n",
    "print(f\"\\nCluster-robust F-stat for Z_lottery (conditional): {f_statistic:.2f} (p = {p_f:.4g})\")\n",
    "print(f\"Cluster-robust t-stat for Z_lottery:                 {t_statistic:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37596dcd-eef4-49c0-b25f-526f53b1a20e",
   "metadata": {},
   "source": [
    "# LaTeX Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f131d3f-32f5-46e5-b1c6-bde39a66af8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "LATEX CODE FOR TABLE 1 (FIRST STAGE)\n",
      "==============================\n",
      "\n",
      "\\begin{table}[htbp]\n",
      "\\centering\n",
      "\\caption{First Stage Effect of Lottery on Medicaid Enrollment}\n",
      "\\label{tab:first_stage}\n",
      "\\begin{tabular}{lcc}\n",
      "\\hline \\hline\n",
      " & (1) & (2) \\\\\n",
      "Dependent Variable: & \\multicolumn{2}{c}{Enrolled in Medicaid} \\\\\n",
      "Specification: & Unadjusted & \\textbf{Design-Adjusted} \\\\\n",
      "\\hline\n",
      " & & \\\\\n",
      "Lottery Win ($Z$) & 0.318*** & 0.325*** \\\\\n",
      " & (0.007) & (0.007) \\\\\n",
      " & & \\\\\n",
      "Household Size Control & No & Yes \\\\\\\\\n",
      "\\hline\n",
      "Control Mean ($Z=0$) & 0.131 & 0.131 \\\\\n",
      "F-Statistic (Cluster) & 2021.8 & 2140.9 \\\\\n",
      "Observations & 16,579 & 16,579 \\\\\n",
      "\\hline \\hline\n",
      "\\multicolumn{3}{p{0.6\\textwidth}}{\\footnotesize \\textit{Notes:} Standard errors clustered at the household level in parentheses. Column (2) controls for \\texttt{numhh\\_list} (household size on the lottery list), which is mechanically related to the probability that at least one household member receives an offer. *** p$<0.01$.}\n",
      "\\end{tabular}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "# def get_balance_row(df, var, label):\n",
    "#     grp = df.groupby('Z_lottery')[var]\n",
    "#     mean_0 = grp.mean()[0]\n",
    "#     mean_1 = grp.mean()[1]\n",
    "    \n",
    "#     var_0 = grp.var()[0]\n",
    "#     var_1 = grp.var()[1]\n",
    "#     sd_pooled = np.sqrt(0.5 * var_0 + 0.5 * var_1)\n",
    "    \n",
    "#     diff = mean_1 - mean_0\n",
    "#     std_diff = diff / sd_pooled\n",
    "    \n",
    "#     # Formatting: special cases if you ever want them\n",
    "#     if 'birthyear' in var:\n",
    "#         m0_str = f\"{mean_0:.0f}\"\n",
    "#         m1_str = f\"{mean_1:.0f}\"\n",
    "#         diff_str = f\"{diff:.1f}\"\n",
    "#     else:\n",
    "#         # log debt and all other continuous vars: 3 decimals\n",
    "#         m0_str = f\"{mean_0:.3f}\"\n",
    "#         m1_str = f\"{mean_1:.3f}\"\n",
    "#         diff_str = f\"{diff:.3f}\"\n",
    "        \n",
    "#     return f\"{label} & {m0_str} & {m1_str} & {diff_str} & {std_diff:.3f} \\\\\\\\\"\n",
    "\n",
    "\n",
    "# Model 1: Raw\n",
    "m1 = smf.ols('W_medicaid ~ Z_lottery', data=df_analysis_sample).fit(\n",
    "    cov_type='cluster', cov_kwds={'groups': df_analysis_sample['household_id']}\n",
    ")\n",
    "\n",
    "# Model 2: Adjusted (Design-adjusted: add numhh_list)\n",
    "df_fs = df_analysis_sample.dropna(subset=['numhh_list'])\n",
    "m2 = smf.ols('W_medicaid ~ Z_lottery + numhh_list', data=df_fs).fit(\n",
    "    cov_type='cluster', cov_kwds={'groups': df_fs['household_id']}\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"LATEX CODE FOR TABLE 1 (FIRST STAGE)\")\n",
    "print(\"=\"*30 + \"\\n\")\n",
    "\n",
    "# Cluster-robust first-stage F for Z_lottery only\n",
    "F1 = float(m1.f_test(\"Z_lottery = 0\").fvalue)\n",
    "F2 = float(m2.f_test(\"Z_lottery = 0\").fvalue)\n",
    "\n",
    "control_mean = df_analysis_sample.loc[df_analysis_sample['Z_lottery'] == 0, 'W_medicaid'].mean()\n",
    "\n",
    "latex_t2 = [\n",
    "    r\"\\begin{table}[htbp]\",\n",
    "    r\"\\centering\",\n",
    "    r\"\\caption{First Stage Effect of Lottery on Medicaid Enrollment}\",\n",
    "    r\"\\label{tab:first_stage}\",\n",
    "    r\"\\begin{tabular}{lcc}\",\n",
    "    r\"\\hline \\hline\",\n",
    "    r\" & (1) & (2) \\\\\",\n",
    "    r\"Dependent Variable: & \\multicolumn{2}{c}{Enrolled in Medicaid} \\\\\",\n",
    "    r\"Specification: & Unadjusted & \\textbf{Design-Adjusted} \\\\\",\n",
    "    r\"\\hline\",\n",
    "    r\" & & \\\\\",\n",
    "    f\"Lottery Win ($Z$) & {m1.params['Z_lottery']:.3f}*** & {m2.params['Z_lottery']:.3f}*** \\\\\\\\\",\n",
    "    f\" & ({m1.bse['Z_lottery']:.3f}) & ({m2.bse['Z_lottery']:.3f}) \\\\\\\\\",\n",
    "    r\" & & \\\\\",\n",
    "    r\"Household Size Control & No & Yes \\\\\\\\\",\n",
    "    r\"\\hline\",\n",
    "    f\"Control Mean ($Z=0$) & {control_mean:.3f} & {control_mean:.3f} \\\\\\\\\",\n",
    "    f\"F-Statistic (Cluster) & {F1:.1f} & {F2:.1f} \\\\\\\\\",\n",
    "    f\"Observations & {int(m1.nobs):,} & {int(m2.nobs):,} \\\\\\\\\",\n",
    "    r\"\\hline \\hline\",\n",
    "    r\"\\multicolumn{3}{p{0.6\\textwidth}}{\\footnotesize \\textit{Notes:} Standard errors clustered at the household level in parentheses. Column (2) controls for \\texttt{numhh\\_list} (household size on the lottery list), which is mechanically related to the probability that at least one household member receives an offer. *** p$<0.01$.}\",\n",
    "    r\"\\end{tabular}\",\n",
    "    r\"\\end{table}\"\n",
    "]\n",
    "\n",
    "print(\"\\n\".join(latex_t2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181d4614-a8e9-4405-bca7-71224eb130c9",
   "metadata": {},
   "source": [
    "# dTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b66eb6de-ab78-473d-b97e-7d3ff1b6e13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surv_lang_0m\n",
      "English    15739\n",
      "Spanish      840\n",
      "Name: count, dtype: int64\n",
      "surv_lang_0m\n",
      "1    15739\n",
      "0      840\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fix dtype of surv_lang_0m\n",
    "print(df_analysis_sample['surv_lang_0m'].value_counts())\n",
    "\n",
    "df_analysis_sample['surv_lang_0m'] = np.where(\n",
    "    df_analysis_sample['surv_lang_0m'] == 'English', 1, 0)\n",
    "\n",
    "print(df_analysis_sample['surv_lang_0m'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faad019-b3fd-4d1c-924b-b29d1eccb870",
   "metadata": {},
   "source": [
    "# Missing Values: Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b813d44-040c-4537-a6d7-8c8b5cf39957",
   "metadata": {},
   "source": [
    "### Current Missing Value Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b32bcef-9103-486a-aa5a-3d2133a4625a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16579 entries, 5 to 74920\n",
      "Data columns (total 66 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   person_id                    16579 non-null  int64  \n",
      " 1   household_id                 16579 non-null  int64  \n",
      " 2   Z_lottery                    16579 non-null  int8   \n",
      " 3   numhh_list                   16579 non-null  int8   \n",
      " 4   zip_msa_list                 16579 non-null  float64\n",
      " 5   female_list                  16578 non-null  float64\n",
      " 6   birthyear_list               16579 non-null  int16  \n",
      " 7   returned_0m                  16579 non-null  float64\n",
      " 8   surv_lang_0m                 16579 non-null  int64  \n",
      " 9   needmet_med_0m               15814 non-null  float64\n",
      " 10  needmet_rx_0m                16013 non-null  float64\n",
      " 11  rx_num_mod_0m                15328 non-null  float64\n",
      " 12  doc_num_mod_0m               16434 non-null  float64\n",
      " 13  er_num_mod_0m                16425 non-null  float64\n",
      " 14  hosp_num_mod_0m              16416 non-null  float64\n",
      " 15  need_rx_0m                   16438 non-null  float64\n",
      " 16  need_med_0m                  16442 non-null  float64\n",
      " 17  ins_months_0m                16359 non-null  float64\n",
      " 18  health_gen_0m                16095 non-null  float64\n",
      " 19  baddays_phys_0m              15106 non-null  float64\n",
      " 20  baddays_ment_0m              15111 non-null  float64\n",
      " 21  health_chg_0m                16265 non-null  float64\n",
      " 22  dia_dx_0m                    16579 non-null  float64\n",
      " 23  ast_dx_0m                    16579 non-null  float64\n",
      " 24  hbp_dx_0m                    16579 non-null  float64\n",
      " 25  emp_dx_0m                    16579 non-null  float64\n",
      " 26  chf_dx_0m                    16579 non-null  float64\n",
      " 27  dep_dx_0m                    16579 non-null  float64\n",
      " 28  female_0m                    16419 non-null  float64\n",
      " 29  birthyear_0m                 16060 non-null  float64\n",
      " 30  edu_0m                       15858 non-null  float64\n",
      " 31  race_hisp_0m                 16370 non-null  float64\n",
      " 32  race_white_0m                16575 non-null  float64\n",
      " 33  race_black_0m                16576 non-null  float64\n",
      " 34  race_amerindian_0m           16576 non-null  float64\n",
      " 35  race_asian_0m                16576 non-null  float64\n",
      " 36  race_pacific_0m              16576 non-null  float64\n",
      " 37  race_other_qn_0m             16573 non-null  float64\n",
      " 38  employ_0m                    16121 non-null  float64\n",
      " 39  employ_hrs_0m                16378 non-null  float64\n",
      " 40  hhinc_cat_0m                 15869 non-null  float64\n",
      " 41  hhsize_0m                    14948 non-null  float32\n",
      " 42  num19_0m                     15768 non-null  float64\n",
      " 43  cost_any_oop_0m              15264 non-null  float64\n",
      " 44  cost_borrow_0m               16347 non-null  float64\n",
      " 45  cost_any_owe_0m              16444 non-null  float64\n",
      " 46  cost_tot_owe_0m              14235 non-null  float32\n",
      " 47  cost_refused_0m              15793 non-null  float64\n",
      " 48  cost_tot_oop_correct_0m      15264 non-null  float32\n",
      " 49  returned_12m                 16579 non-null  float64\n",
      " 50  weight_12m                   16579 non-null  float32\n",
      " 51  weight_intensive_12m         16579 non-null  float32\n",
      " 52  weight_newlottery_12m        16579 non-null  float32\n",
      " 53  cost_any_owe_12m             16377 non-null  float64\n",
      " 54  cost_tot_owe_12m             13778 non-null  float32\n",
      " 55  cost_borrow_12m              16357 non-null  float64\n",
      " 56  cost_refused_12m             15783 non-null  float64\n",
      " 57  cost_tot_oop_12m             15869 non-null  float32\n",
      " 58  cost_any_oop_12m             16368 non-null  float64\n",
      " 59  hhinc_cat_12m                15803 non-null  float64\n",
      " 60  cost_doc_oop_12m             14941 non-null  float32\n",
      " 61  cost_er_oop_12m              14532 non-null  float32\n",
      " 62  cost_rx_oop_12m              14923 non-null  float32\n",
      " 63  cost_oth_oop_12m             14176 non-null  float32\n",
      " 64  W_medicaid                   16579 non-null  int8   \n",
      " 65  ohp_all_mo_firstn_30sep2009  16579 non-null  int8   \n",
      "dtypes: float32(12), float64(46), int16(1), int64(3), int8(4)\n",
      "memory usage: 7.2 MB\n"
     ]
    }
   ],
   "source": [
    "# info on fully merged respondants\n",
    "df_analysis_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a77f7ff8-6183-49f5-a79a-a431739ac3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total analysis sample size: 16,579\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing_Count</th>\n",
       "      <th>Percent_Missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cost_tot_owe_12m</th>\n",
       "      <td>2801</td>\n",
       "      <td>16.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_oth_oop_12m</th>\n",
       "      <td>2403</td>\n",
       "      <td>14.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_tot_owe_0m</th>\n",
       "      <td>2344</td>\n",
       "      <td>14.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_er_oop_12m</th>\n",
       "      <td>2047</td>\n",
       "      <td>12.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_rx_oop_12m</th>\n",
       "      <td>1656</td>\n",
       "      <td>9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_doc_oop_12m</th>\n",
       "      <td>1638</td>\n",
       "      <td>9.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hhsize_0m</th>\n",
       "      <td>1631</td>\n",
       "      <td>9.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baddays_phys_0m</th>\n",
       "      <td>1473</td>\n",
       "      <td>8.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baddays_ment_0m</th>\n",
       "      <td>1468</td>\n",
       "      <td>8.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_any_oop_0m</th>\n",
       "      <td>1315</td>\n",
       "      <td>7.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_tot_oop_correct_0m</th>\n",
       "      <td>1315</td>\n",
       "      <td>7.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rx_num_mod_0m</th>\n",
       "      <td>1251</td>\n",
       "      <td>7.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num19_0m</th>\n",
       "      <td>811</td>\n",
       "      <td>4.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_refused_12m</th>\n",
       "      <td>796</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_refused_0m</th>\n",
       "      <td>786</td>\n",
       "      <td>4.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hhinc_cat_12m</th>\n",
       "      <td>776</td>\n",
       "      <td>4.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>needmet_med_0m</th>\n",
       "      <td>765</td>\n",
       "      <td>4.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edu_0m</th>\n",
       "      <td>721</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hhinc_cat_0m</th>\n",
       "      <td>710</td>\n",
       "      <td>4.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_tot_oop_12m</th>\n",
       "      <td>710</td>\n",
       "      <td>4.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>needmet_rx_0m</th>\n",
       "      <td>566</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>birthyear_0m</th>\n",
       "      <td>519</td>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_gen_0m</th>\n",
       "      <td>484</td>\n",
       "      <td>2.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employ_0m</th>\n",
       "      <td>458</td>\n",
       "      <td>2.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_chg_0m</th>\n",
       "      <td>314</td>\n",
       "      <td>1.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_borrow_0m</th>\n",
       "      <td>232</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_borrow_12m</th>\n",
       "      <td>222</td>\n",
       "      <td>1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ins_months_0m</th>\n",
       "      <td>220</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_any_oop_12m</th>\n",
       "      <td>211</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_hisp_0m</th>\n",
       "      <td>209</td>\n",
       "      <td>1.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_any_owe_12m</th>\n",
       "      <td>202</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employ_hrs_0m</th>\n",
       "      <td>201</td>\n",
       "      <td>1.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hosp_num_mod_0m</th>\n",
       "      <td>163</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_0m</th>\n",
       "      <td>160</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>er_num_mod_0m</th>\n",
       "      <td>154</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_num_mod_0m</th>\n",
       "      <td>145</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>need_rx_0m</th>\n",
       "      <td>141</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>need_med_0m</th>\n",
       "      <td>137</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_any_owe_0m</th>\n",
       "      <td>135</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_other_qn_0m</th>\n",
       "      <td>6</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_white_0m</th>\n",
       "      <td>4</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_pacific_0m</th>\n",
       "      <td>3</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_amerindian_0m</th>\n",
       "      <td>3</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_black_0m</th>\n",
       "      <td>3</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_asian_0m</th>\n",
       "      <td>3</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_list</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Missing_Count  Percent_Missing\n",
       "cost_tot_owe_12m                  2801            16.89\n",
       "cost_oth_oop_12m                  2403            14.49\n",
       "cost_tot_owe_0m                   2344            14.14\n",
       "cost_er_oop_12m                   2047            12.35\n",
       "cost_rx_oop_12m                   1656             9.99\n",
       "cost_doc_oop_12m                  1638             9.88\n",
       "hhsize_0m                         1631             9.84\n",
       "baddays_phys_0m                   1473             8.88\n",
       "baddays_ment_0m                   1468             8.85\n",
       "cost_any_oop_0m                   1315             7.93\n",
       "cost_tot_oop_correct_0m           1315             7.93\n",
       "rx_num_mod_0m                     1251             7.55\n",
       "num19_0m                           811             4.89\n",
       "cost_refused_12m                   796             4.80\n",
       "cost_refused_0m                    786             4.74\n",
       "hhinc_cat_12m                      776             4.68\n",
       "needmet_med_0m                     765             4.61\n",
       "edu_0m                             721             4.35\n",
       "hhinc_cat_0m                       710             4.28\n",
       "cost_tot_oop_12m                   710             4.28\n",
       "needmet_rx_0m                      566             3.41\n",
       "birthyear_0m                       519             3.13\n",
       "health_gen_0m                      484             2.92\n",
       "employ_0m                          458             2.76\n",
       "health_chg_0m                      314             1.89\n",
       "cost_borrow_0m                     232             1.40\n",
       "cost_borrow_12m                    222             1.34\n",
       "ins_months_0m                      220             1.33\n",
       "cost_any_oop_12m                   211             1.27\n",
       "race_hisp_0m                       209             1.26\n",
       "cost_any_owe_12m                   202             1.22\n",
       "employ_hrs_0m                      201             1.21\n",
       "hosp_num_mod_0m                    163             0.98\n",
       "female_0m                          160             0.97\n",
       "er_num_mod_0m                      154             0.93\n",
       "doc_num_mod_0m                     145             0.87\n",
       "need_rx_0m                         141             0.85\n",
       "need_med_0m                        137             0.83\n",
       "cost_any_owe_0m                    135             0.81\n",
       "race_other_qn_0m                     6             0.04\n",
       "race_white_0m                        4             0.02\n",
       "race_pacific_0m                      3             0.02\n",
       "race_amerindian_0m                   3             0.02\n",
       "race_black_0m                        3             0.02\n",
       "race_asian_0m                        3             0.02\n",
       "female_list                          1             0.01"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values and percentages\n",
    "def missing_report(df_analysis_sample):\n",
    "    missing_report = df_analysis_sample.isna().sum().to_frame(name=\"Missing_Count\")\n",
    "    missing_report[\"Percent_Missing\"] = (missing_report[\"Missing_Count\"] / len(df_analysis_sample) * 100).round(2)\n",
    "    missing_report = (missing_report[missing_report[\"Missing_Count\"] > 0]\n",
    "                .sort_values(\"Percent_Missing\", ascending=False))\n",
    "\n",
    "    print(f\"Total analysis sample size: {len(df_analysis_sample):,}\")\n",
    "    print(\"-\" * 50)\n",
    "    return missing_report  \n",
    "original_missing = missing_report(df_analysis_sample)\n",
    "original_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5703950-27d2-4086-b013-d47068c46d6a",
   "metadata": {},
   "source": [
    "### Outcome Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2548ef86-5b0c-4ad1-9f63-b2740c5cd405",
   "metadata": {},
   "source": [
    "#### Medical Debt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "658e8c1c-d3ff-45ce-b7ff-1a2fbfe449a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning: Debt indicator vs total debt\n",
      "cost_any_owe_12m  cost_tot_owe_12m\n",
      "0.00              0.00                6840\n",
      "1.00              NaN                 2023\n",
      "0.00              NaN                  576\n",
      "1.00              2,000.00             378\n",
      "                  1,000.00             328\n",
      "                                      ... \n",
      "                  337.21                 1\n",
      "                  3,490,110.00           1\n",
      "                  3,200,000.00           1\n",
      "                  800,000.00             1\n",
      "                  400,000.00             1\n",
      "Name: count, Length: 783, dtype: int64\n",
      "--------------------------------------------------\n",
      "\n",
      "After cleaning: Debt indicator vs total debt\n",
      "cost_any_owe_12m  cost_tot_owe_12m\n",
      "0.00              0.00                7416\n",
      "1.00              NaN                 2023\n",
      "                  2,000.00             378\n",
      "                  1,000.00             328\n",
      "                  3,000.00             312\n",
      "                                      ... \n",
      "                  337.21                 1\n",
      "                  3,490,110.00           1\n",
      "                  3,200,000.00           1\n",
      "                  800,000.00             1\n",
      "                  400,000.00             1\n",
      "Name: count, Length: 782, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def medical_debt_fillin(any_tot_col):\n",
    "    print(\"Before cleaning: Debt indicator vs total debt\")\n",
    "    print(df_analysis_sample[any_tot_col].value_counts(dropna=False))\n",
    "    print('-'*50)\n",
    "    # Case A: \"Any debt\" == 0, but total debt missing → set total debt = 0\n",
    "    missing_tot_debt = ((df_analysis_sample[any_tot_col[0]] == 0) &\n",
    "                        (df_analysis_sample[any_tot_col[1]].isna()))\n",
    "    df_analysis_sample.loc[missing_tot_debt, any_tot_col[1]] = 0\n",
    "    \n",
    "    # Case B: total debt == 0, but \"any debt\" missing → set indicator = 0\n",
    "    missing_any_debt = ((df_analysis_sample[any_tot_col[1]] == 0) &\n",
    "                        (df_analysis_sample[any_tot_col[0]].isna()))\n",
    "    df_analysis_sample.loc[missing_any_debt, any_tot_col[0]] = 0\n",
    "    \n",
    "    print(\"\\nAfter cleaning: Debt indicator vs total debt\")\n",
    "    print(df_analysis_sample[[any_tot_col[0], any_tot_col[1]]]\n",
    "          .value_counts(dropna=False))\n",
    "\n",
    "medical_debt_fillin([\"cost_any_owe_12m\", \"cost_tot_owe_12m\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bbf692-99a6-49e4-9b1b-52dc4350f783",
   "metadata": {},
   "source": [
    "#### OOP (Total/Any) Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76682ab1-f8a6-4f56-a4fe-11c6805abddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before cleaning: Any OOP vs total OOP\n",
      "cost_any_oop_12m  cost_tot_oop_12m\n",
      "0.00              0.00                7671\n",
      "1.00              0.00                 549\n",
      "                  NaN                  534\n",
      "                  100.00               297\n",
      "                  200.00               226\n",
      "                                      ... \n",
      "                  24,825.00              1\n",
      "                  25,200.00              1\n",
      "                  19,300.00              1\n",
      "                  20,120.00              1\n",
      "                  20,140.00              1\n",
      "Name: count, Length: 1105, dtype: int64\n",
      "--------------------------------------------------\n",
      "\n",
      "Conflict 1 (total=0, any=1): 549 rows\n",
      "\n",
      "Conflict after correction: 0 rows\n",
      "--------------------------------------------------\n",
      "\n",
      "After cleaning: Any OOP vs total OOP\n",
      "cost_any_oop_12m  cost_tot_oop_12m\n",
      "0.00              0.00                8255\n",
      "1.00              NaN                  534\n",
      "                  100.00               297\n",
      "                  200.00               226\n",
      "                  50.00                220\n",
      "                                      ... \n",
      "                  200,040.00             1\n",
      "                  124,400.00             1\n",
      "                  16,800.00              1\n",
      "                  16,000.00              1\n",
      "                  15,220.00              1\n",
      "Name: count, Length: 1103, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBefore cleaning: Any OOP vs total OOP\")\n",
    "print(df_analysis_sample[[\"cost_any_oop_12m\", \"cost_tot_oop_12m\"]]\n",
    "      .value_counts(dropna=False))\n",
    "print('-'*50)\n",
    "\n",
    "# Conflict : total OOP == 0 but \"any OOP\" == 1\n",
    "oop_conflict = ((df_analysis_sample[\"cost_tot_oop_12m\"] == 0) &\n",
    "                (df_analysis_sample[\"cost_any_oop_12m\"] == 1))\n",
    "print(f\"\\nConflict 1 (total=0, any=1): {oop_conflict.sum()} rows\")\n",
    "\n",
    "# Trust the specific dollar amount (intensive margin) more than the yes/no flag.\n",
    "# So if total == 0, force \"any OOP\" to 0.\n",
    "df_analysis_sample.loc[oop_conflict, \"cost_any_oop_12m\"] = 0\n",
    "\n",
    "# Re-check conflict\n",
    "conflict_after = ((df_analysis_sample[\"cost_tot_oop_12m\"] == 0) &\n",
    "                 (df_analysis_sample[\"cost_any_oop_12m\"] == 1))\n",
    "print(f\"\\nConflict after correction: {conflict_after.sum()} rows\")\n",
    "print('-'*50)\n",
    "# no other conflict from below stats\n",
    "\n",
    "# Now fix NA/incomplete combinations:\n",
    "# Case A: total OOP == 0, \"any OOP\" missing → set any OOP = 0\n",
    "mask = ((df_analysis_sample[\"cost_tot_oop_12m\"] == 0) &\n",
    "        (df_analysis_sample[\"cost_any_oop_12m\"].isna()))\n",
    "df_analysis_sample.loc[mask, \"cost_any_oop_12m\"] = 0\n",
    "\n",
    "# Case B: \"any OOP\" == 0, total OOP missing → set total OOP = 0\n",
    "mask = ((df_analysis_sample[\"cost_any_oop_12m\"] == 0) &\n",
    "        (df_analysis_sample[\"cost_tot_oop_12m\"].isna()))\n",
    "df_analysis_sample.loc[mask, \"cost_tot_oop_12m\"] = 0\n",
    "\n",
    "print(\"\\nAfter cleaning: Any OOP vs total OOP\")\n",
    "print(df_analysis_sample[[\"cost_any_oop_12m\", \"cost_tot_oop_12m\"]]\n",
    "      .value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9090eaaa-ffe6-4e27-9b5e-87c01491a439",
   "metadata": {},
   "source": [
    "#### OOP Total/Component Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1293943b-979b-4184-867f-a8f2c8fcc4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "oop_cols = [\n",
    "    \"cost_doc_oop_12m\",\n",
    "    \"cost_er_oop_12m\",\n",
    "    \"cost_rx_oop_12m\",\n",
    "    \"cost_oth_oop_12m\",\n",
    "]\n",
    "\n",
    "# 1) If total is missing but all components are observed → fill total as their sum\n",
    "tot_na_full_components = (df_analysis_sample[\"cost_tot_oop_12m\"].isna() &\n",
    "                          df_analysis_sample[oop_cols].notna().all(axis=1))\n",
    "df_analysis_sample.loc[tot_na_full_components, \"cost_tot_oop_12m\"] = (\n",
    "    df_analysis_sample.loc[tot_na_full_components, oop_cols].sum(axis=1))\n",
    "\n",
    "# 2) If total == 0 and all components are missing → set components to 0\n",
    "tot_zero_components_na = ((df_analysis_sample[\"cost_tot_oop_12m\"] == 0) &\n",
    "                           df_analysis_sample[oop_cols].isna().all(axis=1))\n",
    "df_analysis_sample.loc[tot_zero_components_na, oop_cols] = 0\n",
    "\n",
    "# 3) If exactly one component is missing and total is observed → back it out as total - sum(other components)\n",
    "one_missing = (df_analysis_sample[\"cost_tot_oop_12m\"].notna() &\n",
    "              (df_analysis_sample[oop_cols].isna().sum(axis=1) == 1))\n",
    "\n",
    "for col in oop_cols:\n",
    "    fill_this = one_missing & df_analysis_sample[col].isna()\n",
    "    if fill_this.any():\n",
    "        other_cols = [c for c in oop_cols if c != col]\n",
    "        df_analysis_sample.loc[fill_this, col] = (\n",
    "            df_analysis_sample.loc[fill_this, \"cost_tot_oop_12m\"] -\n",
    "            df_analysis_sample.loc[fill_this, other_cols].sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d478758-71d3-433e-a9fe-c7ebe22ebbe8",
   "metadata": {},
   "source": [
    "#### Borrow/Skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8bfa77d5-7664-4ddf-96b0-9dd61d616149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'No financial hardship' pattern holds for 4,659 respondents.\n",
      "\n",
      "Missing cost_borrow before: 222\n",
      "Filled 27 cost_borrow = 0 under 'no hardship' pattern.\n",
      "Missing cost_borrow after:  195\n",
      "\n",
      "cost_borrow value counts (post-cleaning):\n",
      "cost_borrow_12m\n",
      "0.00    10852\n",
      "1.00     5532\n",
      "NaN       195\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def borrow_fill(cost_any_tot_owe_oop, borrow_col):\n",
    "    no_financial_hardship = ((df_analysis_sample[cost_any_tot_owe_oop[0]] == 0) &   \n",
    "                             (df_analysis_sample[cost_any_tot_owe_oop[1]] == 0) &   \n",
    "                             (df_analysis_sample[cost_any_tot_owe_oop[2]] == 0) &          \n",
    "                             (df_analysis_sample[cost_any_tot_owe_oop[3]] == 0))   \n",
    "\n",
    "    print(f\"'No financial hardship' pattern holds for \"\n",
    "          f\"{no_financial_hardship.sum():,} respondents.\")\n",
    "    \n",
    "    before_borrow_na = df_analysis_sample[borrow_col].isna().sum()\n",
    "    print(f\"\\nMissing cost_borrow before: {before_borrow_na:,}\")\n",
    "    \n",
    "    borrow_fill0 = (df_analysis_sample[borrow_col].isna() & no_financial_hardship)\n",
    "    \n",
    "    df_analysis_sample.loc[borrow_fill0, borrow_col] = 0\n",
    "    \n",
    "    after_borrow_na = df_analysis_sample[borrow_col].isna().sum()\n",
    "    print(f\"Filled {borrow_fill0.sum():,} cost_borrow = 0 \"\n",
    "          f\"under 'no hardship' pattern.\")\n",
    "    print(f\"Missing cost_borrow after:  {after_borrow_na:,}\")\n",
    "    \n",
    "    print(\"\\ncost_borrow value counts (post-cleaning):\")\n",
    "    print(df_analysis_sample[borrow_col].value_counts(dropna=False))\n",
    "\n",
    "borrow_fill([\"cost_any_owe_12m\", \"cost_tot_owe_12m\", \"cost_any_oop_12m\", \"cost_tot_oop_12m\"], \"cost_borrow_12m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53383816-e37b-4a4c-ad01-98b98b6adf37",
   "metadata": {},
   "source": [
    "### Covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c845774-5041-4207-a36b-c1f0e7b6bb50",
   "metadata": {},
   "source": [
    "#### Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8e368bb-e3d5-47fa-a7e3-cbd7471cf665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Race columns found: ['race_hisp_0m', 'race_white_0m', 'race_black_0m', 'race_amerindian_0m', 'race_asian_0m', 'race_pacific_0m', 'race_other_qn_0m']\n",
      "2235 respondents selected more than one race/ethnicity.\n",
      "16462 respondents selected at least one race.\n"
     ]
    }
   ],
   "source": [
    "race_cols = [c for c in df_analysis_sample.columns \n",
    "             if c.startswith(\"race_\") and c.endswith(\"_0m\")]\n",
    "print(f\"Race columns found: {race_cols}\")\n",
    "\n",
    "race_sums = df_analysis_sample[race_cols].sum(axis=1)\n",
    "multiracial_count = (race_sums > 1).sum()\n",
    "print(f\"{multiracial_count} respondents selected more than one race/ethnicity.\")\n",
    "\n",
    "answered_race = (df_analysis_sample[race_cols].sum(axis=1) >= 1)\n",
    "print(f\"{answered_race.sum()} respondents selected at least one race.\")\n",
    "\n",
    "df_analysis_sample.loc[answered_race, race_cols] = (\n",
    "    df_analysis_sample.loc[answered_race, race_cols].fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c150d089-b284-481e-8f6c-04a01b958ac2",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50bf6570-ae1a-4c37-a9dd-90b5615b473b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employ_0m  employ_hrs_0m\n",
      "0.00       1.00             8326\n",
      "1.00       4.00             4352\n",
      "           3.00             1753\n",
      "           2.00             1474\n",
      "NaN        1.00              166\n",
      "1.00       NaN               128\n",
      "NaN        4.00               98\n",
      "1.00       1.00               88\n",
      "NaN        2.00               78\n",
      "           NaN                73\n",
      "           3.00               43\n",
      "Name: count, dtype: int64\n",
      "employ_0m  employ_hrs_0m\n",
      "0.00       1.00             8326\n",
      "1.00       4.00             4450\n",
      "           3.00             1796\n",
      "           2.00             1552\n",
      "NaN        1.00              166\n",
      "1.00       NaN               128\n",
      "           1.00               88\n",
      "NaN        NaN                73\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# if employ_0m = 0 --> emply_hrs_0m = 1\n",
    "# if emply_hrs_0m = 2,3,4 --> employ_0m =1\n",
    "# if employ_hrs = 1 -x-> employ_0m = 0 maybe sick leave\n",
    "\n",
    "print(df_analysis_sample[['employ_0m', 'employ_hrs_0m']].value_counts(dropna=False))\n",
    "\n",
    "not_employed = (df_analysis_sample['employ_0m'] == 0) & (df_analysis_sample['employ_hrs_0m'].isna())\n",
    "df_analysis_sample.loc[not_employed, 'employ_hrs_0m'] = 1.0\n",
    "\n",
    "high_hours = df_analysis_sample['employ_hrs_0m'].isin([2, 3, 4]) \n",
    "df_analysis_sample.loc[high_hours & df_analysis_sample['employ_0m'].isna(), 'employ_0m'] = 1.0\n",
    "\n",
    "print(df_analysis_sample[['employ_0m', 'employ_hrs_0m']].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a55dc5-c8f7-4dbc-89a3-1bf3aa1ede82",
   "metadata": {},
   "source": [
    "#### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5414b787-18eb-4d33-8d62-60540a3bdcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prioritizing 0m survey over signup card\n",
    "no_female = (df_analysis_sample['female_0m'].isna()) & (df_analysis_sample['female_list'].notna())\n",
    "df_analysis_sample.loc[no_female, 'female_0m'] = df_analysis_sample.loc[no_female, 'female_list']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28574d0-923f-434d-b878-2eb4654bf45f",
   "metadata": {},
   "source": [
    "#### Birthday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db4f1fb6-85be-4b9a-8055-74e3d09278b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prioritizing 0m survey over signup card\n",
    "no_bd = (df_analysis_sample['birthyear_0m'].isna()) & (df_analysis_sample['birthyear_list'].notna())\n",
    "df_analysis_sample.loc[no_bd, 'birthyear_0m'] = df_analysis_sample.loc[no_bd, 'birthyear_list']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fb6f3d-a7a8-4d80-8b32-b9c00f654385",
   "metadata": {},
   "source": [
    "#### RX Medication - Covariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c54222d5-10e1-4183-96a6-1b8c488de21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) If num_mod > 0, then need must be 1 (trust realized use)\n",
    "num_pos = df_analysis_sample[\"rx_num_mod_0m\"] > 0\n",
    "need_fix = num_pos & (\n",
    "                   df_analysis_sample[\"need_rx_0m\"].isna() | (df_analysis_sample[\"need_rx_0m\"] == 0))\n",
    "df_analysis_sample.loc[need_fix, \"need_rx_0m\"] = 1\n",
    "\n",
    "# 2) If need == 0 and num_mod is missing, set num_mod = 0\n",
    "need0_num_na = ((df_analysis_sample[\"need_rx_0m\"] == 0) &\n",
    "                  df_analysis_sample[\"rx_num_mod_0m\"].isna())\n",
    "df_analysis_sample.loc[need0_num_na, \"rx_num_mod_0m\"] = 0\n",
    "\n",
    "# 3) If num_mod == 0 and need is missing, set need = 0\n",
    "num0_need_na = ((df_analysis_sample[\"rx_num_mod_0m\"] == 0) &\n",
    "                 df_analysis_sample[\"need_rx_0m\"].isna())\n",
    "df_analysis_sample.loc[num0_need_na, \"need_rx_0m\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6e3a80-bd40-42fa-92ba-3a22839208f2",
   "metadata": {},
   "source": [
    "#### Medical Debt - Covariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef78a2d5-320b-4010-be71-a4c93982ef6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning: Debt indicator vs total debt\n",
      "cost_any_owe_0m  cost_tot_owe_0m\n",
      "0.00             0.00               6539\n",
      "1.00             NaN                2197\n",
      "                 2,000.00            411\n",
      "                 1,000.00            370\n",
      "                 300.00              341\n",
      "                                    ... \n",
      "                 2,700,000.00          1\n",
      "                 1,000,000.00          1\n",
      "                 710,000.00            1\n",
      "                 140,000.00            1\n",
      "                 135,000.00            1\n",
      "Name: count, Length: 861, dtype: int64\n",
      "--------------------------------------------------\n",
      "\n",
      "After cleaning: Debt indicator vs total debt\n",
      "cost_any_owe_0m  cost_tot_owe_0m\n",
      "0.00             0.00               6551\n",
      "1.00             NaN                2197\n",
      "                 2,000.00            411\n",
      "                 1,000.00            370\n",
      "                 300.00              341\n",
      "                                    ... \n",
      "                 205.00                1\n",
      "                 12.65                 1\n",
      "                 199.00                1\n",
      "                 203.00                1\n",
      "                 0.50                  1\n",
      "Name: count, Length: 860, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "medical_debt_fillin([\"cost_any_owe_0m\", \"cost_tot_owe_0m\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab00166-f054-42f6-ba2b-b70fffec2463",
   "metadata": {},
   "source": [
    "#### OOP (any/Total) Costs - Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9175996a-bc20-4443-94a4-263db604450b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost_any_oop_0m  cost_tot_oop_correct_0m\n",
      "0.00             0.00                       4827\n",
      "NaN              NaN                        1315\n",
      "1.00             300.00                      298\n",
      "                 100.00                      260\n",
      "                 200.00                      231\n",
      "                                            ... \n",
      "                 462.00                        1\n",
      "                 8.80                          1\n",
      "                 7.77                          1\n",
      "                 461.00                        1\n",
      "                 5.05                          1\n",
      "Name: count, Length: 1659, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_analysis_sample[[\"cost_any_oop_0m\", \"cost_tot_oop_correct_0m\"]]\n",
    "      .value_counts(dropna=False))\n",
    "\n",
    "# no conflicts. nothing to correct for"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a80d430-e960-4c15-858e-d30ab93b83a9",
   "metadata": {},
   "source": [
    "#### Borrow/Skip - Covariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8661314c-db85-483f-9948-812da4d7112d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'No financial hardship' pattern holds for 2,755 respondents.\n",
      "\n",
      "Missing cost_borrow before: 232\n",
      "Filled 13 cost_borrow = 0 under 'no hardship' pattern.\n",
      "Missing cost_borrow after:  219\n",
      "\n",
      "cost_borrow value counts (post-cleaning):\n",
      "cost_borrow_0m\n",
      "0.00    9172\n",
      "1.00    7188\n",
      "NaN      219\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "borrow_fill([\"cost_any_owe_0m\", \"cost_tot_owe_0m\", \"cost_any_oop_0m\", \"cost_tot_oop_correct_0m\"], \"cost_borrow_0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb2ddb7-68f2-4699-bdb3-ee4c67db4a20",
   "metadata": {},
   "source": [
    "### New Missing Values Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8ccf716-ef93-4e96-91c6-0860ffff16dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total analysis sample size: 16,579\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing_Count_Pre</th>\n",
       "      <th>Missing_Count_Post</th>\n",
       "      <th>Fixed_Count</th>\n",
       "      <th>Fixed_Pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cost_tot_owe_12m</th>\n",
       "      <td>2801</td>\n",
       "      <td>2225</td>\n",
       "      <td>576</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_oth_oop_12m</th>\n",
       "      <td>2403</td>\n",
       "      <td>1862</td>\n",
       "      <td>541</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>birthyear_0m</th>\n",
       "      <td>519</td>\n",
       "      <td>0</td>\n",
       "      <td>519</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_er_oop_12m</th>\n",
       "      <td>2047</td>\n",
       "      <td>1792</td>\n",
       "      <td>255</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cost_doc_oop_12m</th>\n",
       "      <td>1638</td>\n",
       "      <td>1398</td>\n",
       "      <td>240</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Missing_Count_Pre  Missing_Count_Post  Fixed_Count  Fixed_Pct\n",
       "cost_tot_owe_12m               2801                2225          576         20\n",
       "cost_oth_oop_12m               2403                1862          541         22\n",
       "birthyear_0m                    519                   0          519        100\n",
       "cost_er_oop_12m                2047                1792          255         12\n",
       "cost_doc_oop_12m               1638                1398          240         14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Showing only first 10 cols, numbers (percentages) are rounded\n"
     ]
    }
   ],
   "source": [
    "comparison = original_missing.join(missing_report(df_analysis_sample), lsuffix='_Pre', rsuffix='_Post', how='outer')\n",
    "comparison.fillna(0, inplace=True)\n",
    "comparison['Fixed_Count'] = (comparison['Missing_Count_Pre'] - comparison['Missing_Count_Post'])\n",
    "comparison['Fixed_Pct'] = np.where(comparison['Missing_Count_Pre'] > 0,\n",
    "                                  (comparison['Fixed_Count'] / comparison['Missing_Count_Pre'] * 100).round(1),0)\n",
    "display(comparison[['Missing_Count_Pre', 'Missing_Count_Post', 'Fixed_Count', 'Fixed_Pct']]\n",
    "                                  .sort_values('Fixed_Count', ascending=False).astype(int).head())\n",
    "print(\"Note: Showing only first 10 cols, numbers (percentages) are rounded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e45bb0-c334-419a-8f9e-7a916ee4d906",
   "metadata": {},
   "source": [
    "# Organize and Drop columns Before Imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff828ebb-4f3b-4404-b184-360355d9d2db",
   "metadata": {},
   "source": [
    "### Organizing Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd11c7f2-5ef8-435d-ab4b-6a3b8e35d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['returned_12m', 'returned_0m', 'female_list', 'birthyear_list']\n",
    "             \n",
    "identification_cols = ['person_id', 'household_id', 'numhh_list', 'Z_lottery', 'W_medicaid',\n",
    "                       'weight_intensive_12m', 'weight_newlottery_12m','weight_12m', 'ohp_all_mo_firstn_30sep2009']\n",
    "   \n",
    "\n",
    "Y_cols = ['cost_any_owe_12m', 'cost_tot_owe_12m', 'cost_borrow_12m', \n",
    "          'cost_refused_12m', 'cost_tot_oop_12m', 'cost_any_oop_12m', \n",
    "          'hhinc_cat_12m', 'cost_doc_oop_12m', 'cost_er_oop_12m', \n",
    "          'cost_rx_oop_12m', 'cost_oth_oop_12m']\n",
    "\n",
    "X_cols = ['surv_lang_0m', 'needmet_med_0m', 'needmet_rx_0m', 'need_rx_0m', 'need_med_0m',\n",
    "          'rx_num_mod_0m', 'doc_num_mod_0m', 'er_num_mod_0m', 'hosp_num_mod_0m', \n",
    "          'ins_months_0m', 'health_gen_0m', 'baddays_phys_0m', 'baddays_ment_0m', 'health_chg_0m',\n",
    "          'dia_dx_0m', 'ast_dx_0m', 'hbp_dx_0m', 'emp_dx_0m', 'chf_dx_0m', 'dep_dx_0m', \n",
    "          'female_0m', 'birthyear_0m', 'edu_0m', \n",
    "          'race_hisp_0m', 'race_white_0m', 'race_black_0m', 'race_amerindian_0m', 'race_asian_0m', 'race_pacific_0m', 'race_other_qn_0m', \n",
    "          'employ_0m', 'employ_hrs_0m', 'hhinc_cat_0m', \n",
    "          'hhsize_0m', 'num19_0m', 'cost_tot_oop_correct_0m', 'cost_borrow_0m', 'cost_any_owe_0m', 'cost_tot_owe_0m', 'cost_refused_0m', 'cost_any_oop_0m',\n",
    "          'zip_msa_list']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c85c769-f5c2-4bdd-8d2a-a840a075d645",
   "metadata": {},
   "source": [
    "### Col Sanity Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc77e61b-4036-409a-9231-5ab38f81642f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Column Integrity Report ---\n",
      "\n",
      "All DataFrame columns are accounted for.\n",
      "\n",
      "All list columns exist in the DataFrame.\n",
      "\n",
      "No overlaps between lists.\n"
     ]
    }
   ],
   "source": [
    "all_listed = set(drop_cols + identification_cols + Y_cols + X_cols)\n",
    "df_actual = set(df_analysis_sample.columns)\n",
    "print(\"--- Column Integrity Report ---\")\n",
    "\n",
    "# Check A: Are any columns in the DF missing from lists?\n",
    "missing_from_lists = df_actual - all_listed\n",
    "if missing_from_lists:\n",
    "    print(f\"\\n{len(missing_from_lists)} columns in original df but not in lists:\")\n",
    "    print(sorted(list(missing_from_lists)))\n",
    "else:\n",
    "    print(\"\\nAll DataFrame columns are accounted for.\")\n",
    "\n",
    "# Check B: Are any columns in lists missing from the DF? \n",
    "missing_from_df = all_listed - df_actual\n",
    "if missing_from_df:\n",
    "    print(f\"\\n{len(missing_from_df)} columns in lists are not in original df:\")\n",
    "    print(sorted(list(missing_from_df)))\n",
    "else:\n",
    "    print(\"\\nAll list columns exist in the DataFrame.\")\n",
    "\n",
    "# Check C: Overlaps \n",
    "all_cols_flat = drop_cols + identification_cols + Y_cols + X_cols\n",
    "counts = Counter(all_cols_flat)\n",
    "duplicates = [col for col, count in counts.items() if count > 1]\n",
    "\n",
    "if duplicates:\n",
    "    print(f\"Found duplicated columns across lists:\")\n",
    "    print(duplicates)\n",
    "else:\n",
    "    print(\"\\nNo overlaps between lists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abba33f0-282d-42d2-b7a5-dcbf4d0d106e",
   "metadata": {},
   "source": [
    "### Drop Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b230e82e-9f34-4521-b7de-69a2bce63bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis_sample = df_analysis_sample.drop(drop_cols, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2cd08f-77a2-41d3-b6f0-8cea2434dac1",
   "metadata": {},
   "source": [
    "### Col Renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75e419b8-4ba6-442f-9516-44f8f167018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_map = {}\n",
    "# Prefix X variables\n",
    "for col in X_cols:\n",
    "    if col in df_analysis_sample.columns:\n",
    "        rename_map[col] = f\"X_{col}\"\n",
    "# Prefix Y variables\n",
    "for col in Y_cols:\n",
    "    if col in df_analysis_sample.columns:\n",
    "        rename_map[col] = f\"Y_{col}\"\n",
    "\n",
    "# 2. Execute Renaming\n",
    "df_analysis_sample.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "X_cols = [f\"X_{c}\" for c in X_cols if f\"X_{c}\" in df_analysis_sample.columns]\n",
    "Y_cols = [f\"Y_{c}\" for c in Y_cols if f\"Y_{c}\" in df_analysis_sample.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49db7c6-cbbc-42ee-8478-58d9d6587503",
   "metadata": {},
   "source": [
    "# Missing Values: Part 2 (Imputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66789a67-f615-43d3-b7fb-86bb1df389d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to impute: 32 / 42\n",
      "Created flag for X_need_med_0m: 0.83% missing\n",
      "Created flag for X_needmet_med_0m: 4.61% missing\n",
      "Created flag for X_need_rx_0m: 0.51% missing\n",
      "Created flag for X_needmet_rx_0m: 3.41% missing\n",
      "Created flag for X_employ_0m: 1.44% missing\n",
      "Created flag for X_race_hisp_0m: 0.46% missing\n",
      "Created flag for X_race_white_0m: 0.02% missing\n",
      "Created flag for X_race_black_0m: 0.02% missing\n",
      "Created flag for X_race_amerindian_0m: 0.02% missing\n",
      "Created flag for X_race_asian_0m: 0.02% missing\n",
      "Created flag for X_race_pacific_0m: 0.02% missing\n",
      "Created flag for X_race_other_qn_0m: 0.02% missing\n",
      "Created flag for X_cost_borrow_0m: 1.32% missing\n",
      "Created flag for X_cost_any_owe_0m: 0.81% missing\n",
      "Created flag for X_cost_refused_0m: 4.74% missing\n",
      "Created flag for X_cost_any_oop_0m: 7.93% missing\n",
      "Created flag for X_rx_num_mod_0m: 7.55% missing\n",
      "Created flag for X_doc_num_mod_0m: 0.87% missing\n",
      "Created flag for X_er_num_mod_0m: 0.93% missing\n",
      "Created flag for X_hosp_num_mod_0m: 0.98% missing\n",
      "Created flag for X_hhsize_0m: 9.84% missing\n",
      "Created flag for X_num19_0m: 4.89% missing\n",
      "Created flag for X_health_gen_0m: 2.92% missing\n",
      "Created flag for X_health_chg_0m: 1.89% missing\n",
      "Created flag for X_hhinc_cat_0m: 4.28% missing\n",
      "Created flag for X_edu_0m: 4.35% missing\n",
      "Created flag for X_employ_hrs_0m: 1.21% missing\n",
      "Created flag for X_baddays_phys_0m: 8.88% missing\n",
      "Created flag for X_baddays_ment_0m: 8.85% missing\n",
      "Created flag for X_ins_months_0m: 1.33% missing\n",
      "Created flag for X_cost_tot_owe_0m: 14.07% missing\n",
      "Created flag for X_cost_tot_oop_correct_0m: 7.93% missing\n",
      "Total missing-flag columns: 32\n",
      "[IterativeImputer] Completing matrix with shape (16579, 43)\n",
      "[IterativeImputer] Change: 56666712.36798003, scaled tolerance: 1000000.0 \n",
      "[IterativeImputer] Change: 21786848.493672803, scaled tolerance: 1000000.0 \n",
      "[IterativeImputer] Change: 19343772.042765915, scaled tolerance: 1000000.0 \n",
      "[IterativeImputer] Change: 16821381.85826835, scaled tolerance: 1000000.0 \n",
      "[IterativeImputer] Change: 13317673.93556217, scaled tolerance: 1000000.0 \n",
      "[IterativeImputer] Change: 22524570.40095768, scaled tolerance: 1000000.0 \n",
      "[IterativeImputer] Change: 23501915.484550953, scaled tolerance: 1000000.0 \n",
      "[IterativeImputer] Change: 28940947.383060694, scaled tolerance: 1000000.0 \n",
      "[IterativeImputer] Change: 17082379.77340599, scaled tolerance: 1000000.0 \n",
      "[IterativeImputer] Change: 19084061.275618583, scaled tolerance: 1000000.0 \n",
      "[IterativeImputer] Completing matrix with shape (16579, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\anaconda\\envs\\dev\\lib\\site-packages\\sklearn\\impute\\_iterative.py:895: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clipped X_cost_tot_owe_0m to [0.00, 14079641.95]\n",
      "Clipped X_cost_tot_oop_correct_0m to [0.00, 82600.21]\n",
      "\n",
      "Post-processing data types...\n",
      "\n",
      "=== VALIDATION ===\n",
      "Remaining missing values: 0\n",
      "Imputation successful: 16579 rows, 42 covariates + 32 flags\n"
     ]
    }
   ],
   "source": [
    "col_schema = {\n",
    "    'binary' :     ['X_need_med_0m', 'X_needmet_med_0m', 'X_need_rx_0m', 'X_needmet_rx_0m',\n",
    "                    'X_dia_dx_0m', 'X_ast_dx_0m', 'X_hbp_dx_0m', 'X_emp_dx_0m', 'X_chf_dx_0m',\n",
    "                    'X_dep_dx_0m', 'X_female_0m', 'X_employ_0m', 'X_zip_msa_list', \n",
    "                    'X_race_hisp_0m', 'X_race_white_0m', 'X_race_black_0m', 'X_race_amerindian_0m',\n",
    "                    'X_race_asian_0m', 'X_race_pacific_0m', 'X_race_other_qn_0m', \n",
    "                    'X_cost_borrow_0m', 'X_cost_any_owe_0m', 'X_cost_refused_0m', 'X_cost_any_oop_0m'],\n",
    "    'count' :      ['X_rx_num_mod_0m', 'X_doc_num_mod_0m', 'X_er_num_mod_0m','X_hosp_num_mod_0m',\n",
    "                    'X_hhsize_0m', 'X_num19_0m'],\n",
    "    'ordinal' :    ['X_surv_lang_0m', 'X_health_gen_0m', 'X_health_chg_0m', 'X_birthyear_0m',\n",
    "                    'X_hhinc_cat_0m', 'X_edu_0m', 'X_employ_hrs_0m',\n",
    "                    'X_baddays_phys_0m', 'X_baddays_ment_0m', 'X_ins_months_0m'],\n",
    "    'continuous' : ['X_cost_tot_owe_0m', 'X_cost_tot_oop_correct_0m']\n",
    "}\n",
    "\n",
    "all_x_cols = [col for group in col_schema.values() for col in group]\n",
    "\n",
    "# Identifying cols with missingness\n",
    "def get_cols_with_missing(df, cols):\n",
    "    return [c for c in cols if df[c].isna().sum() > 0]\n",
    "\n",
    "cols_to_impute = get_cols_with_missing(df_analysis_sample, all_x_cols)\n",
    "print(f\"Columns to impute: {len(cols_to_impute)} / {len(all_x_cols)}\")\n",
    "\n",
    "# Creating missingness flags\n",
    "missing_flag_cols = []\n",
    "for col in cols_to_impute:\n",
    "    flag_col = f\"{col}_missing\"\n",
    "    df_analysis_sample[flag_col] = df_analysis_sample[col].isna().astype(np.int8)\n",
    "    missing_flag_cols.append(flag_col)\n",
    "    print(f\"Created flag for {col}: {df_analysis_sample[col].isna().mean():.2%} missing\")\n",
    "\n",
    "print(f\"Total missing-flag columns: {len(missing_flag_cols)}\")\n",
    "\n",
    "# Original ranges for ordinal variables\n",
    "orig_dtypes = df_analysis_sample[all_x_cols].dtypes.to_dict()\n",
    "\n",
    "orig_minmax = {col: (df_analysis_sample[col].min(skipna=True), df_analysis_sample[col].max(skipna=True))\n",
    "                   for col in col_schema['ordinal'] if col in cols_to_impute}\n",
    "\n",
    "# Configuring imputer\n",
    "ets = ExtraTreesRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=4,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    n_jobs=-1)\n",
    "\n",
    "imputer = IterativeImputer(\n",
    "    estimator=ets,\n",
    "    max_iter=10,\n",
    "    tol=1e-3,\n",
    "    initial_strategy='median',\n",
    "    imputation_order='ascending',\n",
    "    add_indicator=False,  # Created own flags\n",
    "    random_state=42,\n",
    "    verbose=1)\n",
    "\n",
    "# Impute using full safe sample\n",
    "clean_x_cols = [c for c in all_x_cols if c not in cols_to_impute]\n",
    "valid_aux = ['numhh_list']\n",
    "cols_for_model = clean_x_cols + valid_aux + cols_to_impute\n",
    "X_full_context = df_analysis_sample[cols_for_model].copy()\n",
    "imputer.fit(X_full_context)\n",
    "X_imputed_array = imputer.transform(X_full_context)\n",
    "X_imputed = pd.DataFrame(\n",
    "    X_imputed_array,\n",
    "    columns=cols_for_model,\n",
    "    index=df_analysis_sample.index)\n",
    "\n",
    "df_analysis_sample[cols_to_impute] = X_imputed[cols_to_impute]\n",
    "\n",
    "# Clip continuous variables\n",
    "for col in col_schema['continuous']:\n",
    "    if col in cols_to_impute:\n",
    "        low_cap = df_analysis_sample[col].quantile(0.01)\n",
    "        high_cap = df_analysis_sample[col].quantile(0.99)\n",
    "        df_analysis_sample[col] = df_analysis_sample[col].clip(lower=low_cap, upper=high_cap)\n",
    "        print(f\"Clipped {col} to [{low_cap:.2f}, {high_cap:.2f}]\")\n",
    "\n",
    "# Enforce data types\n",
    "print(\"\\nPost-processing data types...\")\n",
    "\n",
    "# Binary\n",
    "for col in (c for c in col_schema['binary'] if c in cols_to_impute):\n",
    "    df_analysis_sample[col] = df_analysis_sample[col].round().clip(0, 1).astype(np.int8)\n",
    "\n",
    "# Counts\n",
    "for col in (c for c in col_schema['count'] if c in cols_to_impute):\n",
    "    df_analysis_sample[col] = df_analysis_sample[col].round().clip(lower=0).astype(np.int16)\n",
    "\n",
    "# Ordinal: round, clip to original range, cast back to original dtype\n",
    "for col, (low, high) in orig_minmax.items():\n",
    "    dtype = orig_dtypes[col]   \n",
    "    df_analysis_sample[col] = (\n",
    "        df_analysis_sample[col]\n",
    "        .round()\n",
    "        .clip(low, high)\n",
    "        .astype(dtype))\n",
    "\n",
    "# Final validation\n",
    "print(\"\\n=== VALIDATION ===\")\n",
    "\n",
    "# Check remaining missingness\n",
    "remaining_nans = df_analysis_sample[all_x_cols].isna().sum().sum()\n",
    "print(f\"Remaining missing values: {remaining_nans}\")\n",
    "assert remaining_nans == 0, \"Imputation failed!\"\n",
    "\n",
    "# Verify flags are binary\n",
    "for col in missing_flag_cols:\n",
    "    if not set(df_analysis_sample[col].unique()).issubset({0, 1}):\n",
    "        raise ValueError(f\"Flag {col} has non-binary values\")\n",
    "\n",
    "# Verify dtypes are correct\n",
    "print(f\"Imputation successful: {df_analysis_sample.shape[0]} rows, \"\n",
    "      f\"{len(all_x_cols)} covariates + {len(missing_flag_cols)} flags\")\n",
    "\n",
    "# Final feature set ready for causal estimation\n",
    "final_features = all_x_cols + missing_flag_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6077f6a9-9753-4701-9d27-6ddb44c9cdee",
   "metadata": {},
   "source": [
    "# New Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6653b968-840c-436d-9048-cf9623eeb17f",
   "metadata": {},
   "source": [
    "### Creating Catostrophic Income Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2dc3bcb-c7d8-4ec4-9a41-97d625dae9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_hhinc_cat_12m  Y_income_num_12m\n",
      "1.00             0.00                2146\n",
      "2.00             1,250.00            1669\n",
      "6.00             11,250.00           1438\n",
      "5.00             8,750.00            1375\n",
      "7.00             13,750.00           1335\n",
      "4.00             6,250.00            1074\n",
      "3.00             3,750.00            1067\n",
      "8.00             16,250.00            926\n",
      "9.00             18,750.00            920\n",
      "NaN              NaN                  776\n",
      "11.00            23,750.00            741\n",
      "10.00            21,250.00            725\n",
      "12.00            26,250.00            539\n",
      "13.00            28,750.00            431\n",
      "14.00            31,250.00            327\n",
      "15.00            33,750.00            229\n",
      "22.00            60,000.00            213\n",
      "16.00            36,250.00            175\n",
      "17.00            38,750.00            148\n",
      "18.00            41,250.00            113\n",
      "19.00            43,750.00             75\n",
      "21.00            48,750.00             73\n",
      "20.00            46,250.00             64\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# MAPPING: OHIE Income Categories to Numeric Midpoints (2008 Dollars)\n",
    "\n",
    "income_map = {\n",
    "    1: 0,       # \"$0\"\n",
    "    2: 1250,    # \"$1 to $2,500\"\n",
    "    3: 3750,    # \"$2,501 to $5,000\"\n",
    "    4: 6250,    # \"$5,001 to $7,500\"\n",
    "    5: 8750,    # \"$7,501 to $10,000\"\n",
    "    6: 11250,   # \"$10,001 to $12,500\"\n",
    "    7: 13750,   # \"$12,501 to $15,000\"\n",
    "    8: 16250,   # \"$15,001 to $17,500\"\n",
    "    9: 18750,   # \"$17,501 to $20,000\"\n",
    "    10: 21250,  # \"$20,001 to $22,500\"\n",
    "    11: 23750,  # \"$22,501 to $25,000\"\n",
    "    12: 26250,  # \"$25,001 to $27,500\"\n",
    "    13: 28750,  # \"$27,501 to $30,000\"\n",
    "    14: 31250,  # \"$30,001 to $32,500\"\n",
    "    15: 33750,  # \"$32,501 to $35,000\"\n",
    "    16: 36250,  # \"$35,001 to $37,500\"\n",
    "    17: 38750,  # \"$37,501 to $40,000\"\n",
    "    18: 41250,  # \"$40,001 to $42,500\"\n",
    "    19: 43750,  # \"$42,501 to $45,000\"\n",
    "    20: 46250,  # \"$45,001 to $47,500\"\n",
    "    21: 48750,  # \"$47,501 to $50,000\"\n",
    "    22: 60000   # \"$50,001 or more\" does not matter\n",
    "}\n",
    "df_analysis_sample['Y_income_num_12m'] = df_analysis_sample['Y_hhinc_cat_12m'].map(income_map)\n",
    "print(df_analysis_sample[['Y_hhinc_cat_12m', 'Y_income_num_12m']].value_counts(dropna=False))\n",
    "Y_cols.append('Y_income_num_12m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d6a3d26-342d-46a1-b47e-0c53f6b8b17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catastrophic Rate: 0.0685\n"
     ]
    }
   ],
   "source": [
    "# DEFINITION: Catastrophic Expenditure = OOP > 30% of Income \n",
    "# Handle division by zero: If income is 0, any OOP > 0 is catastrophic.\n",
    "\n",
    "def calc_catastrophic(row):\n",
    "    income = row['Y_income_num_12m']\n",
    "    oop = row['Y_cost_tot_oop_12m']\n",
    "    \n",
    "    # Missing data check\n",
    "    if pd.isna(income) or pd.isna(oop):\n",
    "        return np.nan\n",
    "        \n",
    "    if income == 0:\n",
    "        return 1 if oop > 0 else 0\n",
    "    \n",
    "    return 1 if (oop / income) > 0.30 else 0\n",
    "\n",
    "df_analysis_sample['Y_catastrophic_exp_12m'] = df_analysis_sample.apply(calc_catastrophic, axis=1)\n",
    "Y_cols.append('Y_catastrophic_exp_12m')\n",
    "print(f\"Catastrophic Rate: {df_analysis_sample['Y_catastrophic_exp_12m'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ee1718-2505-45ee-bb1d-c376e7d3fb0b",
   "metadata": {},
   "source": [
    "### Creating Age Col - Covariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5003878-4be8-4a6e-a44d-a1db65f9bf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age Range: 19.0 to 64.0\n",
      "X_age_0m  X_birthyear_0m\n",
      "48.00     1,960.00          565\n",
      "46.00     1,962.00          550\n",
      "53.00     1,955.00          529\n",
      "47.00     1,961.00          507\n",
      "52.00     1,956.00          500\n",
      "55.00     1,953.00          495\n",
      "49.00     1,959.00          495\n",
      "50.00     1,958.00          492\n",
      "51.00     1,957.00          477\n",
      "54.00     1,954.00          460\n",
      "56.00     1,952.00          443\n",
      "57.00     1,951.00          433\n",
      "45.00     1,963.00          424\n",
      "58.00     1,950.00          412\n",
      "44.00     1,964.00          397\n",
      "59.00     1,949.00          386\n",
      "43.00     1,965.00          382\n",
      "61.00     1,947.00          366\n",
      "42.00     1,966.00          360\n",
      "60.00     1,948.00          356\n",
      "27.00     1,981.00          355\n",
      "39.00     1,969.00          352\n",
      "26.00     1,982.00          348\n",
      "62.00     1,946.00          341\n",
      "28.00     1,980.00          340\n",
      "31.00     1,977.00          340\n",
      "30.00     1,978.00          339\n",
      "29.00     1,979.00          338\n",
      "41.00     1,967.00          336\n",
      "25.00     1,983.00          330\n",
      "33.00     1,975.00          329\n",
      "38.00     1,970.00          324\n",
      "40.00     1,968.00          317\n",
      "37.00     1,971.00          316\n",
      "23.00     1,985.00          310\n",
      "32.00     1,976.00          307\n",
      "34.00     1,974.00          300\n",
      "35.00     1,973.00          299\n",
      "36.00     1,972.00          298\n",
      "24.00     1,984.00          295\n",
      "63.00     1,945.00          282\n",
      "21.00     1,987.00          269\n",
      "22.00     1,986.00          255\n",
      "20.00     1,988.00          216\n",
      "19.00     1,989.00            8\n",
      "64.00     1,944.00            6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_analysis_sample['X_age_0m'] = 2008 - df_analysis_sample['X_birthyear_0m']\n",
    "print(f\"Age Range: {df_analysis_sample['X_age_0m'].min()} to {df_analysis_sample['X_age_0m'].max()}\")\n",
    "print(df_analysis_sample[['X_age_0m', 'X_birthyear_0m']].value_counts(dropna=False))\n",
    "df_analysis_sample = df_analysis_sample.drop('X_birthyear_0m', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab806901-bbb2-48f6-8ed9-412b87623cd0",
   "metadata": {},
   "source": [
    "# Save data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f406572d-3d0a-4891-a50e-05babebd6a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final, clean dataset to a file\n",
    "file_name = \"../Data_Used/ohie_full_intermediate_dataset.feather\"\n",
    "df_analysis_sample.to_feather(file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
